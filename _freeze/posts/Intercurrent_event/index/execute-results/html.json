{
  "hash": "acb5bc36efd06eeb83a07121d4bf1629",
  "result": {
    "markdown": "---\ntitle: \"Estimation Methods for Intercurrent Events\"\nauthor: \"Yujing Gao\"\ndate: \"2025-09-15\"\ncategories: [intercurrent event, per-protocol method, causal inference, principal stratification, multiple robust]\nimage: \"relationship.png\"\n---\n\n\n::: {style=\"text-align: justify;\"}\n## 1. The General Introduction of Estimand Framework\n\nThe general introduction of estimand framework includes four parts:\n\n-   Trial Objective\n\n-   Estimand\n\n-   Main Estimator\n\n-   Main Estimate\n\nAn **estimand** is a precise description of the treatment effect reflecting the clinical question posed by a given clinical trial objective, via specifying five attributes: Population, Treatment, Endpoint, Population-level Summary, Intercurrent Events.\n\nThe **intercurrent event** is an event that occurs after treatment initiation and affects either the interpretation or existence of the measurements associated with the clinical outcome.\n\nThere are **five strategies (page 101-118 of ICH E9)** to deal with intercurrent events: treatment policy, hypothetical, composite variable, while on treatment, principal stratum. We will introduce these five strategies in next Section.\n\n## 2. The Five Strategies\n\n### 2.1 Treatment Policy\n\nThe treatment policy strategy includes all post-randomization data, regardless of the intercurrent events. In this approach, the primary analysis treats the occurrence of intercurrent events as part of the real-world scenario. Thus, data is collected and analyzed as if all patients followed the initial treatment assignment, irrespective of deviations. (Intention to treat - ITT)\n\nExample: A clinical trial where patients switch to a different medication due to adverse effects, but all data (pre- and post-switch) are included in the primary analysis.\n\n\n::: {.cell layout-align=\"center\" paged.print='false'}\n::: {.cell-output-display}\n![](stg1.png){fig-align='center'}\n:::\n:::\n\n\n### 2.2 Hypothetical\n\nThe hypothetical strategy considers what the outcome would have been if the intercurrent event had not occurred. This strategy relies on assumptions to model the data based on a scenario where patients had continued as initially intended, disregarding the actual intercurrent events.\n\nExample: Estimating the effect of a drug assuming that all patients remained on the assigned treatment without any dropouts or additional medications.\n\nThe hypothetical scenario should consider reasonable situations, e.g. a scenario where a toxic medicine is considered to be non-toxic is not usually relevant for decision making.\n\n\n::: {.cell layout-align=\"center\" paged.print='false'}\n::: {.cell-output-display}\n![](stg2.png){fig-align='center'}\n:::\n:::\n\n\n### 2.3 Composite Variable\n\nIn the composite variable strategy, the intercurrent event is integrated into the outcome itself, redefining it as part of a combined endpoint. This method allows for a new outcome that includes both the clinical endpoint and the intercurrent event, allowing analyses to capture their joint effect.\n\nExample: For a heart disease trial, combining hospitalization and mortality as a composite endpoint, rather than separating them, captures the total adverse outcomes.\n\n\n::: {.cell layout-align=\"center\" paged.print='false'}\n::: {.cell-output-display}\n![](stg3.png){fig-align='center'}\n:::\n:::\n\n\n### 2.4 While-on-Treatment\n\nThe while-on-treatment strategy (also known as the on-treatment strategy) restricts analysis to data collected up until the occurrence of the intercurrent event. Once the intercurrent event occurs, further data is excluded from the analysis. This approach only considers the efficacy of the treatment while patients are actively taking it.\n\nExample: Including data from patients only while they adhere to the medication and excluding data collected after discontinuation or switch to another treatment.\n\n\n::: {.cell layout-align=\"center\" paged.print='false'}\n::: {.cell-output-display}\n![](stg4.png){fig-align='center'}\n:::\n:::\n\n\n### 2.5 Principal Stratum\n\nThe principal stratum strategy analyzes only a specific subset of patients defined by their response to the intercurrent event, such as those who would not experience the event regardless of the treatment they received. This strategy requires assumptions about which patients would fall into this subset and generally involves a more complex statistical model.\n\nExample: In a study where some patients are likely to need additional therapy, the analysis might focus only on those who would not require additional therapy regardless of the treatment arm they are in.\n\n\n::: {.cell layout-align=\"center\" paged.print='false'}\n::: {.cell-output-display}\n![](stg5.png){fig-align='center'}\n:::\n:::\n\n\n## 3. An Simple Example\n\nPrimary Estimand: to assess the outcome of new medicine (treatment group) as compared to old medicine (control group) in defined population who complete the treatment regimen.\n\n\n::: {.cell layout-align=\"center\" paged.print='false'}\n::: {.cell-output-display}\n![](simple_exp.png){fig-align='center'}\n:::\n:::\n\n\n## 4. Principal Stratification Framework\n\n### 4.1. Principal Strata\n\nUnder the potential outcome framework (Rubin; 1974), each subject has potential outcomes $S(z)$ and $Y(z)$, where $z=0,1$. Frangakis and Rubin (2002) defined the principal stratification variable, $U=S(1)S(0)$, where $S(0),S(1)\\in\\{0,1\\}$. Thus, there are four principal strata:\n\n-   $U=00$: Never-adherence\n\n-   $U=10$: Treatment-benefit adherence\n\n-   $U=01$: Control-benefit adherence\n\n-   $U=11$: Always-adherence\n\nTake $U=S(1)S(0) = 00$ Never-adherence as an example:\n\n-   $S(1) = 0$: when subject is assigned to the treatment group, she/he will not adhere to the protocol.\n\n-   $S(0) = 0$: when subject is assigned to the control group, she/he will not adhere to the protocol.\n\nBelow we show the relationship between principal strata and the observed strata.\n\n\n::: {.cell layout-align=\"center\" paged.print='false'}\n::: {.cell-output-display}\n![](relationship.png){fig-align='center'}\n:::\n:::\n\n\n### 4.2. Principal Causal Effects (PCEs)\n\nThe causal estimand here is defined as principal causal effects (PCEs): $$\\tau_{U=S(1)S(0)} = E\\{Y(1) - Y(0) | U = S(1)S(0)\\},\\quad S(1)S(0) = 00, 10, 11, 01.$$\n\nIn Section 2's example, our interested parameter is PCE in Always-adherence strata: $$\\tau_{11} = \\tau_{U=11} = E\\{Y(1) - Y(0)| U= 11\\}.$$\n\n### 4.3. Per-protocol Method\n\nHere we also list the target estimand in Per-protocol method using our notation: $$\\tau_{pp} = E(Y|Z=1,S=1) - E(Y|Z=0,S=1)$$\n\nIn Section 2's example, the interested parameter in the Per-protocol method corresponding to PCE in Always-adherence strata is: $$\\tau_{11} = \\tau_{U=11} = E\\{Y(1) - Y(0)| U= 11\\}.$$\n\nHowever, $\\tau_{11}$ is defined on the potential principal strata $U=S(1)S(0) = 11$, while $\\tau_{pp}$ is defined on the observed strata $(Z,S)$.\n\nHere we can use a simple table to show the relationship between principal strata abd observed strata:\n\n\n::: {.cell layout-align=\"center\" paged.print='false'}\n::: {.cell-output-display}\n![](simple_table.png){fig-align='center'}\n:::\n:::\n\n\nThus, if we use the Per-protocol method to estimate $\\tau_{11}$, $\\widehat{\\tau}_{pp}$ may not be an consistent estimator for $\\tau_{11}$ since it will be confounded by two other principal strata $U = 01$ and $U=10$.\n\n## 5. Principal Stratification Estimation Methods\n\n### 5.1 Identification Assumptions\n\nWe first represent the identification assumptions for the principal causal effects (Jiang et al.; 2022).\n\n-   **Assumption 1**: SUTVA (Stable Unit Treatment Value Assumption): There is no interference and no hidden variations of treatment.\n\n    -   This assumption hold in the completely randomized trial.\n\n-   **Assumption 2**: Treatment Ignorability: $Z\\perp \\{S(0), S(1), Y(0), Y(1)\\}| \\boldsymbol{X}$.\n\n    -   This assumption hold in the completely randomized trial.\n\n-   **Assumption 3**: Monotonicity: $S(1)\\geq S(0)$.\n\n    -   This rules out stratum U=01 (Control-benefit adherence).\n    -   This means: when participants are assigned to the treatment group, they are more likely to adhere to protocol comparing with when participants are assigned to the control group.\n    -   Under Assumption 3, the relationship table between the principal strata and the observed strata changed.\n    -   Now $\\tau_{pp}$ is still confounded by the principal strata $U=10$.\n\n\n::: {.cell layout-align=\"center\" paged.print='false'}\n::: {.cell-output-display}\n![](relationship1.png){fig-align='center'}\n:::\n:::\n\n\n-   **Assumption 4**: Principal Ignorability: $$E\\{Y(1) | U=11, \\boldsymbol{X}\\} = E\\{Y(1) | U=10, \\boldsymbol{X}\\} $$ $$E\\{Y(0) | U=00, \\boldsymbol{X}\\} = E\\{Y(0) | U=10, \\boldsymbol{X}\\} $$\n\n    -   This requires that the expectations of the potential outcome do not vary across some principal strata U conditional on the covariates.\n    -   Take the first formula as an example. Under Assumption 1-3, the first formula is equivalent to \\begin{align*}\n         Z=1,S=1:\\quad  & E\\{Y(1)| U = 11, Z=1,S=1, \\boldsymbol{X}\\} \\\\\n         = &  E\\{Y(1)| U = 10, Z=1, S=1, \\boldsymbol{X}\\}\\\\\n         = &  E\\{Y | Z=1,S=1,\\boldsymbol{X}\\}.\n         \\end{align*}\n    -   This assumption help build an bridge to connect observed data with potential outcome. Thus, we can use observed data to estimate the principal causal effect.\n\n\n::: {.cell layout-align=\"center\" paged.print='false'}\n::: {.cell-output-display}\n![](relationship2.png){fig-align='center'}\n:::\n:::\n\n\n### 5.2. Most Recent Principal Stratification Methods:\n\nUnder the identification assumptions listed in Section 5.1, we present the corresponding estimation methods and provide one plot to show the relationship among these methods.\n\n\n::: {.cell layout-align=\"center\" paged.print='false'}\n::: {.cell-output-display}\n![](recent_method.png){fig-align='center'}\n:::\n:::\n\n\n#### 5.2.0 Notations\n\nBefore we provide the formula of each estimation method, we first provide the following notation based on the observed data $\\boldsymbol{X}$, $Z$, $S$, and $Y$.\n\nDefine:\n\n-   the propensity score of $Z$ or the treatment probability given the covariates: $\\pi(\\boldsymbol{X}) = P(Z=1|\\boldsymbol{X})$.\n\n-   the probability of the intermediate variable $S$ conditional on the treatment and covariates: $p_z(\\boldsymbol{X}) = P(S=1|Z=z,\\boldsymbol{X})$ for $z=0,1$.\n\n-   the principal score of $S$: $$\n    e_{10}(\\boldsymbol{X}) = p_1(\\boldsymbol{X}) - p_0(\\boldsymbol{X}),\\quad e_{00}(\\boldsymbol{X}) = 1- p_1(\\boldsymbol{X}), \\quad e_{11}(\\boldsymbol{X}) = p_0(\\boldsymbol{X}).\n    $$\n\n-   the outcome mean within the observed group ($Z=z,S=s$): $\\mu_{zs}(\\boldsymbol{X}) = E(Y|Z=z, S=s,\\boldsymbol{X})$ for $z,s=0,1$.\n\n-   the marginalized probability of $S$ over the distribution of the covariates: $p_z = E\\{p_z(\\boldsymbol{X})\\}$ for $z=0,1$.\n\n#### 5.2.1 Principal Score Methods (Ding et al.; 2017)\n\nThe two estimators provided in Ding et al. (2017) rely on the principal score model for $S$, $p(\\boldsymbol{X})$, and the outcome mean model for $Y$, the linear model fitted by $\\beta \\boldsymbol{X}$.\n\n\n::: {.cell layout-align=\"center\" paged.print='false'}\n::: {.cell-output-display}\n![](method1.png){fig-align='center'}\n:::\n:::\n\n\n#### 5.2.2 Multiple Robust Methods (Jiang et al.; 2017)\n\nFirst, we list two estimators that rely on the propensity score model for Z, $\\pi(\\boldsymbol{X})$, and the principal score model for S, $p(\\boldsymbol{X})$.\n\n\n::: {.cell layout-align=\"center\" paged.print='false'}\n::: {.cell-output-display}\n![](method2.png){fig-align='center'}\n:::\n:::\n\n\nSecond, we introduce two estimators that rely on the outcome mean model for Y, $\\mu(\\boldsymbol{X})$, and the principal score model for S, $p(\\boldsymbol{X})$.\n\n\n::: {.cell layout-align=\"center\" paged.print='false'}\n::: {.cell-output-display}\n![](method3.png){fig-align='center'}\n:::\n:::\n\n\nFinally, we present the multiple robust estimator, which relies on all three models: the propensity score model for Z, $\\pi(\\boldsymbol{X})$; the principal score model for S, $p(\\boldsymbol{X})$; the outcome mean model for Y, $\\mu(\\boldsymbol{X})$.\n\n\n::: {.cell layout-align=\"center\" paged.print='false'}\n::: {.cell-output-display}\n![](method4.png){fig-align='center'}\n:::\n:::\n\n\n## 6. Simple Simulation\n\nIn this section, we use an simple simulation to show the codes for these principal stratification estimation methods and the Per-protocol method.\n\n### 6.1 Simulation Setting\n\nWe follow the setting in Section 2.1, where we have three baseline variables:\n\n-   $X_1$: Sex, binary, Bernoulli distribution with probability 0.5 as 1 (female)\n\n-   $X_2$: Some transformed variable, binary, Bernoulli distribution with probability 0.8 as 1\n\n-   $X_3$: Age, continuous, normal distribution with mean 50 and variance 8\n\nIn addition, we use the logistic model to generate the intercurrent event:\n\n$$P(S=1|Z, \\boldsymbol{X}) = logistic(-1 + Z +0.6X_1 - 0.4 X_2 + 0.02*X_3 )$$ and we use the linear regression model to generate the observed outcome:\n\n$$ Y = 0.5 - 0.3Z + 0.7S + 0.2X_1 -0.2 X_2 + 0.01X_3 + 0.1X_1Z + 0.01 X_3 S + \\epsilon$$ where $\\epsilon\\sim N(0, \\sigma^2 = 0.4^2)$.\n\nUnder this simulation setting, we represent the following R code to generate the simulated data.\n\n\n::: {.cell paged.print='false'}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\n###################################\n######  Simulation function  ######\n\nS_coef_simu <- c(-1, # intercept,\n                 1, # coef of Z, \n                 0.6, # coef of Sex, \n                 -0.4, # coef of Trans,\n                 0.02 # coef of Age\n                 )\nY_coef_simu <-  c(0.5, # intercept,\n                  -0.3, # coef of Z\n                  0.7, # coef of S\n                  0.2, # coef of Sex\n                  -0.2, # coef of Trans\n                  0.01, # coef of Age\n                  0.1, # coef of Sex * Z\n                  0.01 # coef of Age * S \n)\n\n# Based on vaccine data, we have 3 baseline covariates:\n#  Sex (binary), transformed variable (binary), age (continuous)\nf_sim <- function(N = 200*2, # sample size for two groups\n                  seed = 123, # random seed\n                  pi_Z = 0.5, # treatment propensity score: ratio of treatment / control, constant\n                  male_p = 0.5, # ratio of male\n                  trans_p = 0.8, # ratio of transformed variable\n                  age_mu = 50, # mean of age\n                  age_sd = 4, # sd of age\n                  S_coef = S_coef_simu,\n                  Y_coef = Y_coef_simu, \n                  Y_sd = 0.4\n){\n  \n  set.seed(seed)\n  \n  ## Generate baseline variables\n  Sex <- rbinom(n = N, size = 1, prob = male_p) # 1 means male, 0 means female\n  Trans <- rbinom(n = N, size = 1, prob = trans_p) \n  Age <- rnorm(n = N, mean = age_mu, sd = age_sd)\n  \n  ## Generate treatment assignment Z (Z = 1, treatment)\n  Z <- rbinom(N, size = 1, prob = pi_Z) \n\n  ## Generate intermediate variable (S = 1, adherence)\n  XZ_matrix <- matrix(c(rep(1, N), \n                        Z,\n                        Sex,\n                        Trans,\n                        Age),\n                        nrow = N, \n                        byrow = F)\n  S_prob <-  1 / (1 + exp(- XZ_matrix %*% S_coef))\n  S <- apply(S_prob, 1, function(prob){\n     rbinom(1, size = 1, prob = prob)\n  })\n\n  ## Generate outcome Y\n  XZS_matrix <- matrix(c(rep(1, N), \n                       Z,\n                       S,\n                       Sex,\n                       Trans,\n                       Age,\n                       Sex * Z,\n                       Age * S),\n                    nrow = N, \n                    byrow = F)\n  Y_mu <- XZS_matrix %*% Y_coef \n  Y <- rnorm(N, mean = Y_mu, sd = Y_sd)\n  \n  data <- data.frame(Z,\n                     Sex,\n                     Trans,\n                     Age,\n                     S,\n                     Y\n  )\n  \n  return(data)\n  \n}\n\ndata_simu <- f_sim(N = 1000*2)\nhead(data_simu)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Z Sex Trans      Age S         Y\n1 1   0     1 47.95359 1 1.3793805\n2 0   1     1 50.94775 1 2.6175356\n3 1   0     1 47.83364 0 0.2012383\n4 0   1     1 54.87691 1 2.2561450\n5 1   1     1 50.69654 1 2.2554773\n6 1   0     1 47.53893 1 1.4075605\n```\n:::\n:::\n\n\n### 6.2 True Value Calculation\n\nWe also provide the code for calculating the true values of both the per-protocol effect $\\tau_{pp}$ and each principal causal effect $\\tau_{11}$, $\\tau_{10}$, $\\tau_{00}$.\n\nFirst, for the true value of the per-protocol method $\\tau_{pp}$, we generate a large simulated data with sample size $10^6$ and then calculate the true value of $\\tau_{pp}$ as: $$\\tau_{pp}^{true} = \\widehat{E}\\{Y|Z=1,S=1\\} - \\widehat{E}\\{Y|Z=0,S=1\\}.$$\n\n\n::: {.cell paged.print='false'}\n\n```{.r .cell-code}\nset.seed(123)\ndata_true <- f_sim(N = 10^6)\n\n# True value for per-protocol effect\ntau_pp <- mean(filter(data_true, Z == 1, S == 1)$Y) - mean(filter(data_true, Z == 0, S == 1)$Y)\ntau_pp \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.2569127\n```\n:::\n:::\n\n\nNext, for the true value of the principal causal effects $\\tau_{11}$, $\\tau_{10}$ and $\\tau_{00}$. We use the identification result in Theorem 1 provided in Jiang et al. (2022):\n\n-   \n\n    (a) Based on the treatment probability and principal score:\n\n$$\nAlways-adherence: \\tau_{11}^{true} = \n E\\left\\{\\frac{e_{11}(\\boldsymbol{X})}{ p_0} \\frac{S}{p_1(\\boldsymbol{X})} \\frac{Z}{\\pi(\\boldsymbol{X})} Y\\right\\} - E\\left\\{ \\frac{S}{p_0} \\frac{1-Z}{1-\\pi(\\boldsymbol{X})} Y\\right\\}\n$$\n\n$$\nTreatment-benefit-adherence: \\tau_{10}^{true} = E\\left\\{\\frac{e_{10}(\\boldsymbol{X})}{p_1-p_0} \\frac{S}{p_1(\\boldsymbol{X})} \\frac{Z}{\\pi(\\boldsymbol{X})} Y \\right\\} -\nE\\left\\{\\frac{e_{10}(\\boldsymbol{X})}{p_1-p_0} \\frac{1-S}{1-p_0(\\boldsymbol{X})} \\frac{1-Z}{1 - \\pi(\\boldsymbol{X})} Y \\right\\}\n$$\n\n$$\n    Never-adherence: \\tau_{00}^{true} = E\\left\\{\\frac{1-S}{1-p_1} \\frac{Z}{\\pi(\\boldsymbol{X})} Y \\right\\} - \nE\\left\\{\\frac{e_{00}(\\boldsymbol{X})}{1-p_1}\\frac{1-S}{1-p_0(\\boldsymbol{X})} \\frac{1-Z}{1-\\pi(\\boldsymbol{X})} Y \\right\\} \n$$\n\n-   \n\n    (b) Based on the treatment probability and outcome mean: $$\n        Always-adherence: \\tau_{11}^{true} = \n        E\\left[\\frac{S(1-Z)/ \\{1-\\pi(\\boldsymbol{X})\\}}{p_0} \\{\\mu_{10}(\\boldsymbol{X}) - \\mu_{00}(\\boldsymbol{X})\\}\\right] \n        $$\n\n$$\nTreatment-benefit-adherence: \\tau_{10}^{true} = \nE\\left[ \\frac{SZ/\\pi(\\boldsymbol{X}) - S(1-Z)/\\{1-\\pi(\\boldsymbol{X})\\}}{p_1 - p_0} \\left\\{\\mu_{11}(\\boldsymbol{X}) - \\mu_{00}(\\boldsymbol{X})\\right\\}\\right] \n$$\n\n$$\n    Never-adherence: \\tau_{00}^{true} = E\\left[ \\frac{1-SZ/\\pi(\\boldsymbol{X})}{1-p_1} \\{\\mu_{11}(\\boldsymbol{X}) - \\mu_{00}(\\boldsymbol{X})\\} \\right]\n$$\n\n-   \n\n    (c) Based on the principal score and outcome mean: $$\n        Always-adherence: \\tau_{11}^{true} = E\\left[\\frac{p_0(\\boldsymbol{X})}{p_0} \\{\\mu_{11}(\\boldsymbol{X}) - \\mu_{01}(\\boldsymbol{X})\\}\\right] \n        $$\n\n$$\nTreatment-benefit-adherence: \\tau_{10}^{true} = E\\left[\\frac{p_1(\\boldsymbol{X}) - p_0(\\boldsymbol{X}) }{p_1-p_0} \\{\\mu_{11}(\\boldsymbol{X}) - \\mu_{00}(\\boldsymbol{X})\\} \\right]\n$$\n\n$$\n    Never-adherence: \\tau_{00}^{true} = E\\left[\\frac{1-p_1(\\boldsymbol{X})}{1-p_1} \\{\\mu_{10}(\\boldsymbol{X}) - \\mu_{00}(\\boldsymbol{X})\\}\\right] \n$$\n\n\n::: {.cell paged.print='false'}\n\n```{.r .cell-code}\n###### Calculate the true value for PCE ######\n# the true value is not stable in this strata\ntau10 <- function(data,\n                  S_coef = S_coef_simu,\n                  Y_coef = Y_coef_simu){\n  Z <- data$Z\n  S <- data$S\n  Y <- data$Y\n  X1 <- data$Sex\n  X2 <- data$Trans\n  X3 <- data$Age\n  \n  p1_X <- 1 / (1 + exp(- (S_coef[1] + S_coef[2] * 1 + S_coef[3] * X1 + S_coef[4] * X2 + S_coef[5] * X3)))\n  p0_X <- 1 / (1 + exp(- (S_coef[1] + S_coef[2] * 0 + S_coef[3] * X1 + S_coef[4] * X2 + S_coef[5] * X3)))\n  \n  p1 <- mean(p1_X)\n  p0 <- mean(p0_X)\n  \n  e_10_X <- p1_X - p0_X\n  e_00_X <- 1 - p1_X\n  e_11_X <- p0_X\n  \n  mu_11_X <- Y_coef[1] + Y_coef[2] * 1 + Y_coef[3] * 1 + Y_coef[4] * X1 +\n    Y_coef[5] * X2 + Y_coef[6] * X3 + Y_coef[7] * X1 * 1 + Y_coef[8] * X3 * 1\n  mu_00_X <- Y_coef[1] + Y_coef[2] * 0 + Y_coef[3] * 0 + Y_coef[4] * X1 +\n    Y_coef[5] * X2 + Y_coef[6] * X3 + Y_coef[7] * X1 * 0 + Y_coef[8] * X3 * 0\n  \n  res_a <- mean(e_10_X*S*Z*Y / (p1-p0) / p1_X / (1/2) ) - \n          mean(e_10_X * (1-S) * (1-Z) * Y / (p1-p0) / (1-p0_X)/ (1/2))\n  res_b <- mean( ((S * Z / (1/2)) - S * (1 - Z) / (1/2)) * (mu_11_X - mu_00_X) / (p1-p0))\n  res_c <-  mean((p1_X - p0_X) * (mu_11_X - mu_00_X) / (p1 - p0) )\n  \n  return(c(res_a, res_b, res_c))\n}\n\ntau00 <- function(data,\n                  S_coef = S_coef_simu,\n                  Y_coef = Y_coef_simu){\n  Z <- data$Z\n  S <- data$S\n  Y <- data$Y\n  X1 <- data$Sex\n  X2 <- data$Trans\n  X3 <- data$Age\n \n  p1_X <- 1 / (1 + exp(- (S_coef[1] + S_coef[2] * 1 + S_coef[3] * X1 + S_coef[4] * X2 + S_coef[5] * X3)))\n  p0_X <- 1 / (1 + exp(- (S_coef[1] + S_coef[2] * 0 + S_coef[3] * X1 + S_coef[4] * X2 + S_coef[5] * X3)))\n    \n  p1 <- mean(p1_X)\n  p0 <- mean(p0_X)\n  \n  e_00_X <- 1 - p1_X\n  \n  mu_10_X <- Y_coef[1] + Y_coef[2] * 1 + Y_coef[3] * 0 + Y_coef[4] * X1 +\n           Y_coef[5] * X2 + Y_coef[6] * X3 + Y_coef[7] * X1 * 1 + Y_coef[8] * X3 * 0\n  mu_00_X <- Y_coef[1] + Y_coef[2] * 0 + Y_coef[3] * 0 + Y_coef[4] * X1 +\n           Y_coef[5] * X2 + Y_coef[6] * X3 + Y_coef[7] * X1 * 0 + Y_coef[8] * X3 * 0\n  \n  res_a <- mean((1 - S)*Z*Y / (1 - p1)/(1/2)) - mean(e_00_X * (1-S)*(1-Z)*Y / (1-p1) / (1-p0_X)/ (1/2))\n  res_b <- mean( (1 - S*Z/(1/2)) / (1 - p1) *  (mu_10_X - mu_00_X))\n  res_c <- mean((1-p1_X)/(1-p1) * (mu_10_X - mu_00_X) )\n  \n return(c(res_a, res_b, res_c))\n}\n\ntau11 <- function(data, \n                  S_coef = S_coef_simu,\n                  Y_coef = Y_coef_simu){\n  Z <- data$Z\n  S <- data$S\n  Y <- data$Y\n  X1 <- data$Sex\n  X2 <- data$Trans\n  X3 <- data$Age\n  \n  p1_X <- 1 / (1 + exp(- (S_coef[1] + S_coef[2] * 1 + S_coef[3] * X1 + S_coef[4] * X2 + S_coef[5] * X3)))\n  p0_X <- 1 / (1 + exp(- (S_coef[1] + S_coef[2] * 0 + S_coef[3] * X1 + S_coef[4] * X2 + S_coef[5] * X3)))\n  \n  p1 <- mean(p1_X)\n  p0 <- mean(p0_X)\n  \n  e_11_X <- p0_X\n  \n  mu_11_X <- Y_coef[1] + Y_coef[2] * 1 + Y_coef[3] * 1 + Y_coef[4] * X1 +\n    Y_coef[5] * X2 + Y_coef[6] * X3 + Y_coef[7] * X1 * 1 + Y_coef[8] * X3 * 1\n  mu_01_X <- Y_coef[1] + Y_coef[2] * 0 + Y_coef[3] * 1 + Y_coef[4] * X1 +\n    Y_coef[5] * X2 + Y_coef[6] * X3 + Y_coef[7] * X1 * 0 + Y_coef[8] * X3 * 1\n  \n  res_a <- mean(e_11_X*S*Z*Y / p0 / p1_X / (1/2) ) - \n    mean( S * (1-Z) * Y / p0 / (1/2))\n  res_b <- mean( S*(1-Z) / (1/2) / p0 * (mu_11_X - mu_01_X) )\n  res_c <-  mean( p0_X / p0 * (mu_11_X - mu_01_X))\n  \n return(c(res_a, res_b, res_c))\n}\n\ntau11_true <- tau11(data_true)\ntau10_true <- tau10(data_true)\ntau00_true <- tau00(data_true)\n\ntau11_true\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.2465260 -0.2430214 -0.2426083\n```\n:::\n\n```{.r .cell-code}\ntau10_true\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9491897 0.9423639 0.9459625\n```\n:::\n\n```{.r .cell-code}\ntau00_true\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.2604445 -0.2601612 -0.2607295\n```\n:::\n:::\n\n\n### 6.3 Estimation\n\nHere we show R codes for principal stratification estimation. First, for the two estimation methods provided by Ding et al. (2017), below is the original R code provided within their paper:\n\n\n::: {.cell paged.print='false'}\n\n```{.r .cell-code}\n# Ding's original estimation code\n{\n  ##################################################################\n  ######################## EM Algorithm for ########################\n  #### Principal Stratification Analysis using Propensity Score ####\n  ######################## With Monotonicity #######################\n  ###################### Ding and Lu 2015 Oct ######################\n  ##################################################################\n  \n  \n  ##propensity score method, with covariate adjustment and sensitivity analysis for GPI\n  #the package used for multivariate logistic regression\n  library(nnet)\n  \n  #Preliminary function: principal score calculation \n  #Z: randomization\n  #D: treatment received\n  #X: pretreatment covaraites, 11111 in the first column\n  #beta.a, beta.n: initial values for the paramaters in the multiple logistic regression\n  #iter.max: total number of iterations\n  #error0: convergence error rate\n  #Trace: if TRUE then trace each EM iteration\n  #fitting multinomial logistic regression model with principal stratification variable as missing data\n  PS_pred = function(Z, D, X, \n                     beta.a = NULL, beta.n = NULL, \n                     iter.max = 200, error0 = 10^-6, Trace = FALSE) {  \n    V = dim(X)[2]\n    N = length(Z)\n    if(is.null(beta.a)) beta.a = rep(0, V)\n    if(is.null(beta.n)) beta.n = rep(0, V)  \n    \n    iter = 1         \n    repeat{\n      \n      ##initial values of iteration\n      beta.a_old = beta.a\n      beta.n_old = beta.n\n      \n      if(Trace == T) {\n        print(paste(\"The \", iter, \"-th EM iteration!\", sep=\"\"))\n      }\n      \n      #E step: posterior probabilities\n      #and the augmented data set with weights\n      #creat a null matrix for the augmented data set AugData\n      AugData = NULL\n      #each individual correspond to 1 or 2 individuals in the augmented data set\n      for(i in 1:N) {\n        if(Z[i]==1&D[i]==1) {\n          #posterior probabilities\n          prob.c = 1/(1 + exp(t(beta.a_old)%*%X[i, ]))\n          prob.a = 1 - prob.c\n          \n          AugData = rbind(AugData, c(1, X[i, ], prob.c))\n          AugData = rbind(AugData, c(2, X[i, ], prob.a))\n        }\n        \n        if(Z[i]==1&D[i]==0) {\n          AugData = rbind(AugData, c(3, X[i, ], 1))  \n        }\n        \n        if(Z[i]==0&D[i]==1) {\n          AugData = rbind(AugData, c(2, X[i, ], 1))  \n        }\n        \n        if(Z[i]==0&D[i]==0) {\n          #posterior probabilities\n          prob.c = 1/(1 + exp(t(beta.n_old)%*%X[i, ]))\n          prob.n = 1 - prob.c\n          \n          AugData = rbind(AugData, c(1, X[i, ], prob.c))\n          AugData = rbind(AugData, c(3, X[i, ], prob.n))  \n          \n        }#for if\n        \n      }#for \"for\"\n      #make AugData into a dataframe\n      #AugData = data.frame(AugData)\n      #colnames(AugData) = c(\"U\", \"X\", \"Weight\")\n      #Multinomial logistic regression using \"nnet\" package\n      \n      fit = multinom(AugData[, 1] ~ AugData[, (3:(V+1))], weights = AugData[, (V+2)], trace = FALSE)\n      betas  = coef(fit)\n      beta.a = betas[1, ]\n      beta.n = betas[2, ]\n      \n      iter = iter + 1\n      error = sum((beta.a - beta.a_old)^2)  + sum((beta.n - beta.n_old)^2)\n      if(iter>iter.max||error<error0)   break           \n      \n    }#for repeat\n    \n    #the predicted probabilities\n    #three columns corresponding to the adherence, always taker and never taker\n    PROB = matrix(0, N, 3)\n    for(i in 1:N) {\n      prob.c = 1\n      prob.a = exp(t(beta.a)%*%X[i, ])\n      prob.n = exp(t(beta.n)%*%X[i, ])\n      sum = prob.c + prob.a + prob.n\n      \n      PROB[i,] = c(prob.c, prob.a, prob.n)/sum\n    }\n    \n    results = list(PROB=PROB, beta.a=beta.a, beta.n=beta.n)\n    return(results)\n  }\n  \n  #Main function\n  #Z: randomization\n  #D: treatment received\n  #X: covariate matrix: the first column is NOT 11111\n  #Y: outcome of interest\n  #trc: truncation by death indicator, default FALSE. If TRUE only SACE (i.e. AACE) is calculated.\n  #ep1, ep0: sensitivity parameters in Proposition 4, Section 6.1.\n  #beta.a, beta.n: initial values for the paramaters in the multiple logistic regression\n  PSPS_M_weighting = function(Z, D, X, Y, \n                              trc = FALSE, ep1 = 1, ep0 = 1,\n                              beta.a = NULL, beta.n = NULL) {\n    #augment the design X\n    N = length(Z)\n    X = cbind(rep(1, N), X)\n    \n    #estimate the propensity scores using Multinomial Logistic Regression\n    #PS_pred returns three columns: c, a, n\n    ps.score.fit = PS_pred(Z, D, X, beta.a = beta.a, beta.n = beta.n)\n    ps.score     = ps.score.fit$PROB\n    pr.n = sum(Z*(1 - D))/sum(Z)\n    pr.a = sum((1 - Z)*D)/sum(1-Z)\n    pr.c = 1 - pr.n - pr.a\n    \n    #indices\n    index11 = (1:N)[Z==1&D==1]\n    index10 = (1:N)[Z==1&D==0]\n    index01 = (1:N)[Z==0&D==1]\n    index00 = (1:N)[Z==0&D==0]\n    \n    #weights\n    if (trc == F) {\n      w1c = ep1*ps.score[index11, 1]/(ep1*ps.score[index11, 1] + ps.score[index11, 2])/pr.c*(pr.c + pr.a)\n      w0c = ep0*ps.score[index00, 1]/(ep0*ps.score[index00, 1] + ps.score[index00, 3])/pr.c*(pr.c + pr.n)\n      w0n = ps.score[index00, 3]/(ep0*ps.score[index00, 1] + ps.score[index00, 3])/pr.n*(pr.c + pr.n)\n    }\n    w1a = ps.score[index11, 2]/(ep1*ps.score[index11, 1] + ps.score[index11, 2])/pr.a*(pr.c + pr.a)\n    \n    #model assisted regression estimator \n    if (trc == F) {\n      r1c = lm(Y[index11] ~ 0 + X[index11, ], weights = w1c)$coef\n      r0c = lm(Y[index00] ~ 0 + X[index00, ], weights = w0c)$coef\n      r1n = lm(Y[index10] ~ 0 + X[index10, ])$coef\n      r0n = lm(Y[index00] ~ 0 + X[index00, ], weights = w0n)$coef\n    }\n    r1a = lm(Y[index11] ~ 0 + X[index11, ], weights = w1a)$coef\n    r0a = lm(Y[index01] ~ 0 + X[index01, ])$coef\n    \n    #weighted outcomes\n    if (trc == F) {\n      weighted.Y.c1 = Y[index11]*w1c\n      weighted.Y.c0 = Y[index00]*w0c\n      weighted.Y.n0 = Y[index00]*w0n\n    }\n    weighted.Y.a1 = Y[index11]*w1a\n    \n    #CACE, NACE and AACE\n    if (trc == F) {\n      CACE = mean(weighted.Y.c1) - mean(weighted.Y.c0)\n      NACE = mean(Y[index10]) - mean(weighted.Y.n0)\n    }\n    AACE = mean(weighted.Y.a1) - mean(Y[index01])\n    \n    #weighted outcomes for regression estimator\n    if (trc == F) {\n      weighted.Y1c = (Y[index11]-X[index11, ]%*%r1c)*w1c\n      weighted.Y0c = (Y[index00]-X[index00, ]%*%r0c)*w0c\n      weighted.Y1n = Y[index10]-X[index10, ]%*%r1n\n      weighted.Y0n = (Y[index00]-X[index00, ]%*%r0n)*w0n\n      weighted.rc = rbind(X[index11, ]*w1c, X[index00, ]*w0c) %*% (r1c - r0c)\n      weighted.rn = rbind(X[index10, ], X[index00, ]*w0n) %*% (r1n - r0n)\n    }\n    weighted.Y1a = (Y[index11]-X[index11, ]%*%r1a)*w1a\n    weighted.Y0a = Y[index01]-X[index01, ]%*%r0a\n    weighted.ra = rbind(X[index11, ]*w1a, X[index01, ]) %*% (r1a - r0a)\n    \n    #CACE, NACE and AACE, regression estimates\n    if (trc == F) {\n      CACE.reg = mean(weighted.Y1c) - mean(weighted.Y0c) + mean(weighted.rc)\n      NACE.reg = mean(weighted.Y1n) - mean(weighted.Y0n) + mean(weighted.rn)\n    }\n    AACE.reg = mean(weighted.Y1a) - mean(weighted.Y0a) + mean(weighted.ra)\n    \n    #results\n    if (trc == F) {\n      ACE = list(CACE = CACE, CACE.reg = CACE.reg, \n                 NACE = NACE, NACE.reg = NACE.reg, \n                 AACE = AACE, AACE.reg = AACE.reg,  \n                 beta.a = ps.score.fit$beta.a, beta.n = ps.score.fit$beta.n)\n    }\n    else {\n      ACE = list(AACE = AACE, AACE.reg = AACE.reg,  \n                 beta.a = ps.score.fit$beta.a, beta.n = ps.score.fit$beta.n)\n    }\n    return(ACE)\n    \n  }\n}\n```\n:::\n\n\nGiven their estimation functions, we use the simulated data ***data_simu*** to show the application\n\n\n::: {.cell paged.print='false'}\n\n```{.r .cell-code}\nres_PS <- PSPS_M_weighting(Z = data_simu$Z, \n                           D = data_simu$S, \n                           X = as.matrix(data_simu[, 2:4]), \n                           Y = data_simu$Y,\n                           trc = FALSE, \n                           ep1 = 1, \n                           ep0 = 1,\n                           beta.a = NULL,\n                           beta.n = NULL)\n  \nres_PS_11 <- c(res_PS$AACE, res_PS$AACE.reg)\nres_PS_10 <- c(res_PS$CACE, res_PS$CACE.reg)\nres_PS_00 <- c(res_PS$NACE, res_PS$NACE.reg)\n\nres_PS_11\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.2007091 -0.2256450\n```\n:::\n\n```{.r .cell-code}\nres_PS_10\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9685365 0.9630745\n```\n:::\n\n```{.r .cell-code}\nres_PS_00\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.2255630 -0.2216478\n```\n:::\n:::\n\n\nNext, we present the R code for the five estimation methods provided by Jiang et al. (2022), which is in their R pcakge ***pace***. This package can be installed using the following R code and can be found on web page <https://github.com/shuyang-stat/pace>.\n\n\n::: {.cell paged.print='false'}\n\n```{.r .cell-code}\ndevtools::install_github(\"shuyang1987/pace\")\n```\n:::\n\n::: {.cell paged.print='false'}\n\n```{.r .cell-code}\nlibrary(pace)\n    \nres_MR <-  pace::pace(X = as.matrix(data_simu[, c(2:4)]),\n                        Z = data_simu$Z,\n                        S = data_simu$S,\n                        Y = data_simu$Y,\n                        family.Y=\"gaussian\",\n                        nboot = 500 # bootstrap times\n                      )\n\n\nres_MR_11 <- c(res_MR$tau11w, res_MR$tau11sw, res_MR$tau11reg, res_MR$tau11reg2, res_MR$tau11aw)\nres_MR_11\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.2365232 -0.2252102 -0.2243740 -0.2243929 -0.2242910\n```\n:::\n\n```{.r .cell-code}\nres_MR_10 <- c(res_MR$tau10w, res_MR$tau10sw, res_MR$tau10reg, res_MR$tau10reg2, res_MR$tau10aw)\nres_MR_10\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9878232 0.9839751 0.9863116 0.9854472 0.9856981\n```\n:::\n\n```{.r .cell-code}\nres_MR_00 <- c(res_MR$tau00w, res_MR$tau00sw, res_MR$tau00reg, res_MR$tau00reg2, res_MR$tau00aw)\nres_MR_00\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.2122643 -0.2163912 -0.2184721 -0.2192499 -0.2191100\n```\n:::\n:::\n\n\nNow let's combine these 7 estimation results together.\n\n\n::: {.cell paged.print='false'}\n\n```{.r .cell-code}\nEst_res <- data.frame(est_method = c(\"Ding_naive\", \"Ding_reg\", \n                                     \"tau_w\", \"tau_sw\", \"tau_reg\", \"rau_reg2\", \"tau_aw\"),\n                      tau11_est = c(res_PS_11, res_MR_11),\n                      tau11_bias = c(res_PS_11, res_MR_11) - tau11_true,\n                      tau10_est = c(res_PS_10, res_MR_10),\n                      tau10_bias = c(res_PS_10, res_MR_10) - tau10_true,\n                      tau00_est = c(res_PS_00, res_MR_11),\n                      tau00_bias = c(res_PS_00, res_MR_11) - tau00_true)\n\nknitr::kable(Est_res, caption = \"Estimation Result\")\n```\n\n::: {.cell-output-display}\nTable: Estimation Result\n\n|est_method |  tau11_est| tau11_bias| tau10_est| tau10_bias|  tau00_est| tau00_bias|\n|:----------|----------:|----------:|---------:|----------:|----------:|----------:|\n|Ding_naive | -0.2007091|  0.0458169| 0.9685365|  0.0193468| -0.2255630|  0.0348815|\n|Ding_reg   | -0.2256450|  0.0173764| 0.9630745|  0.0207106| -0.2216478|  0.0385134|\n|tau_w      | -0.2365232|  0.0060851| 0.9878232|  0.0418606| -0.2365232|  0.0242063|\n|tau_sw     | -0.2252102|  0.0213158| 0.9839751|  0.0347854| -0.2252102|  0.0352343|\n|tau_reg    | -0.2243740|  0.0186474| 0.9863116|  0.0439477| -0.2243740|  0.0357872|\n|rau_reg2   | -0.2243929|  0.0182154| 0.9854472|  0.0394846| -0.2243929|  0.0363366|\n|tau_aw     | -0.2242910|  0.0222351| 0.9856981|  0.0365084| -0.2242910|  0.0361535|\n:::\n:::\n\n\n## Reference\n\n-   D. B. Rubin. Estimating causal effects of treatments in randomized and nonrandomized studies. J Educ Psychol, 66(5): 688--701, 1974.\n-   C.E. Frangakis and D. B. Rubin. Principal stratification in causal inference. Biometrics, 58(1):21--29, 2002.\n-   P. Ding and J. Lu. Principal stratification analysis using principal scores. Journal of the Royal Statistical Society Series B: Statistical Methodology, 79(3):757--777, 2017.\n-   Z. Jiang, S. Yang, and P. Ding. Multiply robust estimation of causal effects under principal ignorability. Journal of the Royal Statistical Society Series B: Statistical Methodology, 84(4):1423--1445, 2022.\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}