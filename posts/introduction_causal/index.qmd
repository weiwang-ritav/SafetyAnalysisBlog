---
title: "Basic Introduction for Causal Inference (still working)"
author: "Yujing Gao"
date: "2025-09-22"
categories: [causal inference, statistics]
image: "causal_dag.png"
---

## 1. The General Introduction of Estimand Framework

The general introduction of estimand framework includes four parts:

-   Trial Objective

-   Estimand

-   Main Estimator

-   Main Estimate

An **estimand** is a precise description of the treatment effect reflecting the clinical question posed by a given clinical trial objective, via specifying five attributes: Population, Treatment, Endpoint, Population-level Summary, Intercurrent Events.

## 2. Potential Outcome Model

### 2.1 Definition of Potential Outcomes and Causal Effects

The correlation between two variables $X$ and $Y$ can be represented using the join distribution of $X$ and $Y$. For example, the Pearson correlation coefficient is expressed as $\rho(X,Y) = \sigma_{xy}/\sigma_{x}\sigma_{y}$, where \$ \sigma\_{xy}\$ is the covariance between $X$ and $Y$, and $\sigma_{x}, \sigma_{y}$ are the standard deviations of $X$ and $Y$, respectively. But how can we formally express the causal effect between X and Y? Using the joint distribution of the observed variables X and Y does not allow us to clearly define causal effects.

Statisticians have used the potential outcome model to formalize the definition of causal effects. Using this framework, Neyman (1923) provided a mathematical definition of causal effects for experimental studies, and Rubin (1974) extended this definition to observational studies. The potential outcome model typically requires the Stable Unit Treatment Value Assumption (SUTVA): each individual's potential outcomes are unaffected by the treatment assignments of others, and each individual has a well-defined outcome under each possible treatment. See Rubin (1980) for a detailed discussion. Consider a binary treatment or exposure variable T, where T = 1 denotes the treatment group and T = 0 denotes the control group. Let $Y(t)$ denote the outcome under the treatment assignment $T=t$, which is called the **potential outcome**. For each individual, the observed outcome variable Y can be written as $Y = TY(1) + (1-T) Y(0)$. The SUTVA assumption means that the outcome is determined only by one's own treatment and not by others'. However, this assumption may not hold in real-world settings. For instance, someone winning the lottery may impact their co-workers' motivation; a friend getting a flu shot may indirectly reduce your own chance of getting infected. This assumption is one of the key limitations of the potential outcome model. Recently, some researchers have attempted to address this issue using social network methods (Athey et al., 2018; Eckles et al., 2017; Hudgens and Halloran, 2008; Liu and Hudgens, 2014; Sobel, 2006; Tchetgen and VanderWeele, 2012).

Causal effects are typically defined as comparisons between an individual's potential outcomes. The individual causal effect (ICE) for individual i is defined as:

$$ICE_i = Y_i(1) - Y_i(0).$$

Although the potential outcome model clearly defines individual causal effects, as Heraclitus once said: "You cannot step into the same river twice." For each individual, we can only observe one of $Y_i(1)$ or $Y_i(0)$, not both. Therefore, individual causal effects cannot be directly observed and must be inferred from observed data. Despite this limitation, statisticians have proposed various methods to infer individual or subgroup causal effects, usually under strong modeling assumptions. Recently, individualized treatment effects and precision medicine have focused on identifying these effects (Chakraborty and Moodie, 2013; Kleinberg and Hripcsak, 2011; Murphy, 2003; Su et al., 2012). Since we cannot observe both potential outcomes for any one person, causal inference is inherently a problem of missing data. Statisticians are often more concerned with population-level features, such as the average causal effect, which can be defined using the potential outcome framework.

Statistics is concerned with the characteristics of a population. Using potential outcomes, we can also define the average causal effect for the population.

**Definition 2.1** The Average Causal Effect (ACE) for the population is defined as the expectation of the individual causal effect:

$$ACE = E(ICE) = E[Y(1) - Y(0)] = E[Y(1)] - E[Y(0)].$$

The average causal effect is defined as the difference between the average outcome $E[Y(1)]$ if all individuals were assigned to treatment $T=1$ and the average outcome $E[Y(0)]$ if all individuals were assigned to control $T=0$. In practice, it is impossible to have all individuals receive treatment $T=1$ and then later receive control $T=0$; even if this were attempted, for the same individual i, the potential outcome $Y_i(t)$ when first receiving treatment $T=t$ might differ from the potential outcome $Y_i(t)^\prime$ when receiving treatment $T=t$ later.

Furthermore, one might be interested in the average causal effect within a specific subpopulation. For example, the efficacy of a certain drug might differ for different groups, such as males or females.

**Definition 2.2** Let X be a covariate. The average causal effect for the subpopulation with $X=x$ is defined as:

$$E[Y(1) - Y(0)|X = x].$$

Additionally, people are often concerned with the causal effect specifically for the treated group. For instance, epidemiologists might not be interested in the causal effect of smoking on the entire population, but only on the subpopulation who actually smoke.

**Definition 2.3** The Average Causal effect for the Treated (ATT) is defined as:

$$E[Y(1) - Y(0)|T=1].$$ We say the average causal effect:

$$ACE = E[Y(1) - Y(0)]$$ is **identifiable** if the ACE can be uniquely determined from the distribution $P(T,Y,X)$ of the observed variables. If the ACE is not identifiable, it means there exist at least two unequal values $ACE \neq ACE^\prime$ that are both consistent with the observed data. Identifiability is often the most challenging issue in causal inference. To achieve identifiability of causal effects, additional assumptions are typically required. Randomized experiments are the most effective method for identifying causal effects.

<!-- ```{r stg1, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T} -->

<!-- knitr::include_graphics("stg1.png") -->

<!-- ``` -->
