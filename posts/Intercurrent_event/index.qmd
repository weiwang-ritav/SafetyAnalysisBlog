---
title: "Intercurrent Events"
author: "Yujing Gao"
date: "2025-06-05"
categories: [intercurrent event, statistics, causal inference]
---

## 1. The General Introduction of Estimand Framework

The general introduction of estimand framework includes four parts:

-   Trial Objective

-   Estimand

-   Main Estimator

-   Main Estimate

An **estimand** is a precise description of the treatment effect reflecting the clinical question posed by a given clinical trial objective, via specifying five attributes: Population, Treatment, Endpoint, Population-level Summary, Intercurrent Events.

The **intercurrent event** is an event that occurs after treatment initiation and affects either the interpretation or existence of the measurements associated with the clinical outcome.

There are **five strategies (page 101-118 of ICH E9)** to deal with intercurrent events: treatment policy, hypothetical, composite variable, while on treatment, principal stratum.

## 2. The Five Strategies

### 2.1 Treatment Policy

The treatment policy strategy includes all post-randomization data, regardless of the intercurrent events. In this approach, the primary analysis treats the occurrence of intercurrent events as part of the real-world scenario. Thus, data is collected and analyzed as if all patients followed the initial treatment assignment, irrespective of deviations. (Intention to treat - ITT)

Example: A clinical trial where patients switch to a different medication due to adverse effects, but all data (pre- and post-switch) are included in the primary analysis.

```{r stg1, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("stg1.png")
```

### 2.2 Hypothetical

The hypothetical strategy considers what the outcome would have been if the intercurrent event had not occurred. This strategy relies on assumptions to model the data based on a scenario where patients had continued as initially intended, disregarding the actual intercurrent events.

Example: Estimating the effect of a drug assuming that all patients remained on the assigned treatment without any dropouts or additional medications.

The hypothetical scenario should consider reasonable situations, e.g. a scenario where a toxic medicine is considered to be non-toxic is not usually relevant for decision making.

```{r stg2, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("stg2.png")
```

### 2.3 Composite Variable

In the composite variable strategy, the intercurrent event is integrated into the outcome itself, redefining it as part of a combined endpoint. This method allows for a new outcome that includes both the clinical endpoint and the intercurrent event, allowing analyses to capture their joint effect.

Example: For a heart disease trial, combining hospitalization and mortality as a composite endpoint, rather than separating them, captures the total adverse outcomes.

```{r stg3, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("stg3.png")
```

### 2.4 While-on-Treatment

The while-on-treatment strategy (also known as the on-treatment strategy) restricts analysis to data collected up until the occurrence of the intercurrent event. Once the intercurrent event occurs, further data is excluded from the analysis. This approach only considers the efficacy of the treatment while patients are actively taking it.

Example: Including data from patients only while they adhere to the medication and excluding data collected after discontinuation or switch to another treatment.

```{r stg4, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("stg4.png")
```

### 2.5 Principal Stratum

The principal stratum strategy analyzes only a specific subset of patients defined by their response to the intercurrent event, such as those who would not experience the event regardless of the treatment they received. This strategy requires assumptions about which patients would fall into this subset and generally involves a more complex statistical model.

Example: In a study where some patients are likely to need additional therapy, the analysis might focus only on those who would not require additional therapy regardless of the treatment arm they are in.

```{r stg5, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("stg5.png")
```

## 3. An Simple Example

Primary Estimand: to assess the outcome of new medicine (treatment group) as compared to old medicine (control group) in defined population who complete the treatment regimen.

```{r vaccine_exp, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("simple_exp.png")
```

## 4. Principal Stratification Framework

### 4.1. Principal Strata

Under the potential outcome framework (Rubin, 1974), each subject has potential outcomes $S(z)$ and $Y(z)$, where $z=0,1$. Frangakis and Rubin (2002) defined the principal stratification variable, $U=S(1)S(0)$, where $S(0),S(1)\in\{0,1\}$. Thus, there are four principal strata:

 * $U=00$: Never-adherence
 
 * $U=10$: Treatment-benefit adherence
 
 * $U=01$: Control-benefit adherence
 
 * $U=11$: Always-adherence


Take $U=S(1)S(0) = 00$ Never-adherence as an example:

 - $S(1) = 0$: when subject is assigned to the treatment group, she/he will not adhere to the protocol.
 
 - $S(0) = 0$: when subject is assigned to the control group, she/he will not adhere to the protocol.

Below we show the relationship between principal strata and the observed strata.

```{r relationship, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("relationship.png")
```

### 4.2. Principal Causal Effects (PCEs)

The causal estimand here is defined as principal causal effects (PCEs):
$$\tau_{U=S(1)S(0)} = E\{Y(1) - Y(0) | U = S(1)S(0)\},\quad S(1)S(0) = 00, 10, 11, 01.$$

In Section 2's example, our interested parameter is PCE in Always-adherence strata:
$$\tau_{11} = \tau_{U=11} = E\{Y(1) - Y(0)| U= 11\}.$$

### 4.3. Per-protocol Method

Here we also list the target estimand in Per-protocol method using our notation:
$$\tau_{pp} = E(Y|Z=1,S=1) - E(Y|Z=0,S=1)$$

In Section 2's example, the interested parameter in the Per-protocol method corresponding to PCE in Always-adherence strata is:
$$\tau_{11} = \tau_{U=11} = E\{Y(1) - Y(0)| U= 11\}.$$

However, $\tau_{11}$ is defined on the potential principal strata $U=S(1)S(0) = 11$, while $\tau_{pp}$ is defined on the observed strata $(Z,S)$.


Here we can use a simple table to show the relationship between principal strata abd observed strata:

```{r simple_table, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("simple_table.png")
```

Thus, if we use the Per-protocol method to estimate $\tau_{11}$, $\widehat{\tau}_{pp}$ may not be an consistent estimator for $\tau_{11}$ since it will be confounded by two other principal strata $U = 01$ and $U=10$.




## 5. Principal Stratification Estimation Methods

### 5.1. Most Recent Principal Stratification Methods:

Here we first list the most recent principal stratification methods and provide one plot to show 
the relationship among these methods.

```{r recent_method, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("recent_method.png")
```


### 5.2 Identification Assumptions 

 - **Assumption 1**: SUTVA (Stable Unit Treatment Value Assumption): There is no interference and no hidden variations of treatment.
   - This assumption hold in the completely randomized trial.
   
 - **Assumption 2**: Treatment Ignorability: $Z\perp \{S(0), S(1), Y(0), Y(1)\}| \boldsymbol{X}$.
 
   - This assumption hold in the completely randomized trial.
   
 - **Assumption 3**: Monotonicity: $S(1)\geq S(0)$.
   - This rules out stratum U=01 (Control-benefit adherence).
   - This means: when participants are assigned to the treatment group, they are more likely to adhere to protocol comparing with when participants are assigned to the control group.
   - Under Assumption 3, the relationship table between the principal strata and the observed strata changed.
   - Now $\tau_{pp}$ is still confounded by the principal strata $U=10$.
   
```{r relationship1, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("relationship1.png")
```

 - **Assumption 4**: Principal Ignorability: 
 $$E\{Y(1) | U=11, \boldsymbol{X}\} = E\{Y(1) | U=10, \boldsymbol{X}\} $$
 $$E\{Y(0) | U=00, \boldsymbol{X}\} = E\{Y(0) | U=10, \boldsymbol{X}\} $$
 
    - This requires that the expectations of the potential outcome do not vary across some principal strata U conditional on the covariates.
    - Take the first formula as an example. Under Assumption 1-3, the first formula is equivalent to 
    \begin{align*}
    Z=1,S=1:\quad  & E\{Y(1)| U = 11, Z=1,S=1, \boldsymbol{X}\} \\
    = &  E\{Y(1)| U = 10, Z=1, S=1, \boldsymbol{X}\}\\
    = &  E\{Y | Z=1,S=1,\boldsymbol{X}\}.
    \end{align*}
    - This assumption help build an bridge to connect observed data with potential outcome. Thus, we can use observed data to estimate the principal causal effect.

```{r relationship2, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("relationship2.png")
```

### 5.3 Principal Score Methods (Ding et al.; 2017)
```{r method1, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("method1.png")
```

### 5.4 Multiple Robust Methods (Jiang et al.; 2017)

First, we list two estimators that rely on propensity score model for Z and principal score model for S.
```{r method2, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("method2.png")
```

Next, we introduce two estimators that rely on outcome mean model for Y, where \texttt{tau11ref} also relies on propensity score model for Z and \texttt{tau11reg2} relies on principal score model for S.

```{r method3, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("method3.png")
```

Finally, we present the triply robust estimator, which relies on all three models: propensity score model for Z, principal score model for S and outcome mean mdoel for Y.

```{r method4, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("method4.png")
```


## 6. Simple Simulation

In this section, we use an simple simulation to show the codes for these principal stratification estimation methods and the Per-protocol method.

### 6.1 Setting
We follow the setting in Section 2.1, where we have three baseline variables:

 * $X_1$: Sex, binary, Bernoulli distribution with probability 0.5 as 1 (female)
 
 * $X_2$: Some transformed variable, binary, Bernoulli distribution with probability 0.8 as 1
 
 * $X_3$: Age, continuous, normal distribution with mean 50 and variance 8

In addition, we use the logistic model to generate the intercurrent event:

$$P(S=1|Z, \boldsymbol{X}) = logistic(-1 + 0.15Z +0.6X_1 + 0.8 X_2 + 0.05*X_3 )$$
and we use the linear regression model to generate the observed outcome:

$$ Y = 0.5 - 0.7Z + 0.2S - 0.1X_1 +0.2 X_2 + 0.05X_3 + 0.02X_3Z - 0.03 X_3 S + \epsilon$$
where $\epsilon\sim N(0, \sigma^2 = 0.6^2Z + 0.65^2(1-Z))$.

Under this simulation setting, we provide the true values for both the PCEs and the PP.

```{r true_value, message = FALSE, warning = FALSE, paged.print = FALSE, eval = T, include = T}
# need to add true value
```

```{r simu_gen, message = FALSE, warning = FALSE, paged.print = FALSE, eval = T, include = T}
library(dplyr)

###################################
######  Simulation function  ######

# Based on vaccine data, we have 3 baseline covariates:
#  Sex (binary), transformed variable (binary), age (continuous)
f_sim <- function(N = 200*2, # sample size for two groups
                  seed = 123, # random seed
                  pi_Z = 0.5, # treatment propensity score: ratio of treatment / control, constant
                  ctrl_male_p = 0.5, # ratio of male (control)
                  trt_male_p = 0.5, # ratio of male (treat)
                  ctrl_trans_p = 0.8, # ratio of transformed variable (control)
                  trt_trans_p = 0.8, # ratio of transformed variable (treat)
                  ctrl_age_mu = 50, # mean of age (control)
                  ctrl_age_sigma = 8, # sd of age (control)
                  trt_age_mu = 50, # mean of age (treat)
                  trt_age_sigma = 8, # sd of age (treat)
                  S_coef = c(-1, # intercept,
                             0.15, # coef of Z, previous 0.18991, 2 for part2
                             0.6, # coef of Sex, previous 0.57866
                             0.8, # coef of Trans, previous 0.77246
                             0.05 # coef of Age, previous 0.03093
                             # 0.3 # coef of unmeasured confounder
                  ), # coef of S's model - c(intercept, Z, Sex, Trans, Age)
                  Y_coef = c(0.5, # intercept,
                             -0.7, # coef of Z
                             0.2, # coef of S
                             -0.1, # coef of Sex
                             0.2, # coef of Trans
                             0.05, # coef of Age
                             0.02, # coef of Age * Z
                             -0.03 # coef of Age * S 
                  ), 
                  sd_Y_trt = 0.6,
                  sd_Y_ctrl = 0.65
){
  
  logit <- function(y){
  exp(y)/ (exp(y) + 1)
  }
  
  set.seed(seed)
  Nt <- N * pi_Z # sample size of treatment group
  Nc <- N * (1 - pi_Z)  # sample size of control group
  
  ## Generate baseline covariates
  # Generate data for the treatment group
  Trt_Z <-  rep(1, Nt)
  Trt_sex <- rbinom(n = Nt, size = 1, prob = trt_male_p) # 1 means male, 0 means female
  Trt_trans <- rbinom(n = Nt, size = 1, prob = trt_trans_p) 
  Trt_age <- rnorm(n = Nt, mean = trt_age_mu, sd = trt_age_sigma)
  
  # Generate data for the control group
  Ctrl_Z <-  rep(0, Nc)
  Ctrl_sex <- rbinom(n = Nc, size = 1, prob = ctrl_male_p) 
  Ctrl_trans <- rbinom(n = Nc, size = 1, prob = ctrl_trans_p) 
  Ctrl_age <- rnorm(n = Nc, mean = ctrl_age_mu, sd = ctrl_age_sigma)
  
  ## Generate intermediate variable A = 1, adherence
  Trt_X <- matrix(c(rep(1, Nt), 
                    Trt_Z,
                    Trt_sex,
                    Trt_trans,
                    Trt_age),
                    nrow = Nt, 
                    byrow = F)
  Trt_link_S <-  Trt_X %*% S_coef
  Trt_prob_S <- logit(Trt_link_S)
  Trt_S <- rbinom(length(Trt_prob_S), 1, Trt_prob_S)
  
  Ctrl_X <- matrix(c(rep(1, Nc), 
                     Ctrl_Z,
                     Ctrl_sex,
                     Ctrl_trans,
                     Ctrl_age),
                   nrow = Nc, 
                   byrow = F)
  Ctrl_link_S <-  Ctrl_X %*% S_coef
  Ctrl_prob_S <- logit(Ctrl_link_S)
  Ctrl_S <- rbinom(length(Ctrl_prob_S), 1, Ctrl_prob_S)
  
  ## Generate outcome Y - full model
  # generate the residual part
  Trt_res <- rnorm(Nt, mean = 0, sd = sd_Y_trt) 
  Ctrl_res <- rnorm(Nc, mean = 0, sd = sd_Y_ctrl)
  
  Trt_X_Y <- matrix(c(rep(1, Nt), 
                      Trt_Z,
                      Trt_S,
                      Trt_sex,
                      Trt_trans,
                      Trt_age,
                      Trt_age * Trt_Z,
                      Trt_age * Trt_S),
                    nrow = Nt, 
                    byrow = F)
  Trt_Y <- Trt_X_Y %*% Y_coef + Trt_res
  
  Ctrl_X_Y <- matrix(c(rep(1, Nc), 
                       Ctrl_Z,
                       Ctrl_S,
                       Ctrl_sex,
                       Ctrl_trans,
                       Ctrl_age,
                       Ctrl_age * Ctrl_Z,
                       Ctrl_age * Ctrl_S),
                     nrow = Nc, 
                     byrow = F)
  Ctrl_Y <- Ctrl_X_Y %*% Y_coef + Ctrl_res

  data <- data.frame(
    Z = c(Ctrl_Z, Trt_Z),
    Sex = c(Ctrl_sex, Trt_sex),
    Ges = c(Ctrl_trans, Trt_trans),
    Age = c(Ctrl_age, Trt_age),
    S = c(Ctrl_S, Trt_S),
    Y = c(Ctrl_Y, Trt_Y)
  )
  
  return(data)
  
}

data_simu <- f_sim(N = 1000*2)
head(data_simu)

```

### 6.2 Estimation
 
Here we show R codes for principal stratification estimation. First, for the two estimation methods provided by Ding et al. (2017), below is the original R code provided within their paper: 

```{r simu_PS_fun, message = FALSE, warning = FALSE, paged.print = FALSE, eval = T, include = T}
# Ding's original estimation code
{
  ##################################################################
  ######################## EM Algorithm for ########################
  #### Principal Stratification Analysis using Propensity Score ####
  ######################## With Monotonicity #######################
  ###################### Ding and Lu 2015 Oct ######################
  ##################################################################
  
  
  ##propensity score method, with covariate adjustment and sensitivity analysis for GPI
  #the package used for multivariate logistic regression
  library(nnet)
  
  #Preliminary function: principal score calculation 
  #Z: randomization
  #D: treatment received
  #X: pretreatment covaraites, 11111 in the first column
  #beta.a, beta.n: initial values for the paramaters in the multiple logistic regression
  #iter.max: total number of iterations
  #error0: convergence error rate
  #Trace: if TRUE then trace each EM iteration
  #fitting multinomial logistic regression model with principal stratification variable as missing data
  PS_pred = function(Z, D, X, 
                     beta.a = NULL, beta.n = NULL, 
                     iter.max = 200, error0 = 10^-6, Trace = FALSE) {  
    V = dim(X)[2]
    N = length(Z)
    if(is.null(beta.a)) beta.a = rep(0, V)
    if(is.null(beta.n)) beta.n = rep(0, V)  
    
    iter = 1         
    repeat{
      
      ##initial values of iteration
      beta.a_old = beta.a
      beta.n_old = beta.n
      
      if(Trace == T) {
        print(paste("The ", iter, "-th EM iteration!", sep=""))
      }
      
      #E step: posterior probabilities
      #and the augmented data set with weights
      #creat a null matrix for the augmented data set AugData
      AugData = NULL
      #each individual correspond to 1 or 2 individuals in the augmented data set
      for(i in 1:N) {
        if(Z[i]==1&D[i]==1) {
          #posterior probabilities
          prob.c = 1/(1 + exp(t(beta.a_old)%*%X[i, ]))
          prob.a = 1 - prob.c
          
          AugData = rbind(AugData, c(1, X[i, ], prob.c))
          AugData = rbind(AugData, c(2, X[i, ], prob.a))
        }
        
        if(Z[i]==1&D[i]==0) {
          AugData = rbind(AugData, c(3, X[i, ], 1))  
        }
        
        if(Z[i]==0&D[i]==1) {
          AugData = rbind(AugData, c(2, X[i, ], 1))  
        }
        
        if(Z[i]==0&D[i]==0) {
          #posterior probabilities
          prob.c = 1/(1 + exp(t(beta.n_old)%*%X[i, ]))
          prob.n = 1 - prob.c
          
          AugData = rbind(AugData, c(1, X[i, ], prob.c))
          AugData = rbind(AugData, c(3, X[i, ], prob.n))  
          
        }#for if
        
      }#for "for"
      #make AugData into a dataframe
      #AugData = data.frame(AugData)
      #colnames(AugData) = c("U", "X", "Weight")
      #Multinomial logistic regression using "nnet" package
      
      fit = multinom(AugData[, 1] ~ AugData[, (3:(V+1))], weights = AugData[, (V+2)], trace = FALSE)
      betas  = coef(fit)
      beta.a = betas[1, ]
      beta.n = betas[2, ]
      
      iter = iter + 1
      error = sum((beta.a - beta.a_old)^2)  + sum((beta.n - beta.n_old)^2)
      if(iter>iter.max||error<error0)   break           
      
    }#for repeat
    
    #the predicted probabilities
    #three columns corresponding to complier, always taker and never taker
    PROB = matrix(0, N, 3)
    for(i in 1:N) {
      prob.c = 1
      prob.a = exp(t(beta.a)%*%X[i, ])
      prob.n = exp(t(beta.n)%*%X[i, ])
      sum = prob.c + prob.a + prob.n
      
      PROB[i,] = c(prob.c, prob.a, prob.n)/sum
    }
    
    results = list(PROB=PROB, beta.a=beta.a, beta.n=beta.n)
    return(results)
  }
  
  #Main function
  #Z: randomization
  #D: treatment received
  #X: covariate matrix: the first column is NOT 11111
  #U: (latent) principal stratification variable, 1 complier, 2 always taker, 3 never taker
  #Y: outcome of interest
  #trc: truncation by death indicator, default FALSE. If TRUE only SACE (i.e. AACE) is calculated.
  #ep1, ep0: sensitivity parameters in Proposition 4, Section 6.1.
  #beta.a, beta.n: initial values for the paramaters in the multiple logistic regression
  PSPS_M_weighting = function(Z, D, X, Y, 
                              trc = FALSE, ep1 = 1, ep0 = 1,
                              beta.a = NULL, beta.n = NULL) {
    #augment the design X
    N = length(Z)
    X = cbind(rep(1, N), X)
    
    #estimate the propensity scores using Multinomial Logistic Regression
    #PS_pred returns three columns: c, a, n
    ps.score.fit = PS_pred(Z, D, X, beta.a = beta.a, beta.n = beta.n)
    ps.score     = ps.score.fit$PROB
    pr.n = sum(Z*(1 - D))/sum(Z)
    pr.a = sum((1 - Z)*D)/sum(1-Z)
    pr.c = 1 - pr.n - pr.a
    
    #indices
    index11 = (1:N)[Z==1&D==1]
    index10 = (1:N)[Z==1&D==0]
    index01 = (1:N)[Z==0&D==1]
    index00 = (1:N)[Z==0&D==0]
    
    #weights
    if (trc == F) {
      w1c = ep1*ps.score[index11, 1]/(ep1*ps.score[index11, 1] + ps.score[index11, 2])/pr.c*(pr.c + pr.a)
      w0c = ep0*ps.score[index00, 1]/(ep0*ps.score[index00, 1] + ps.score[index00, 3])/pr.c*(pr.c + pr.n)
      w0n = ps.score[index00, 3]/(ep0*ps.score[index00, 1] + ps.score[index00, 3])/pr.n*(pr.c + pr.n)
    }
    w1a = ps.score[index11, 2]/(ep1*ps.score[index11, 1] + ps.score[index11, 2])/pr.a*(pr.c + pr.a)
    
    #model assisted regression estimator 
    if (trc == F) {
      r1c = lm(Y[index11] ~ 0 + X[index11, ], weights = w1c)$coef
      r0c = lm(Y[index00] ~ 0 + X[index00, ], weights = w0c)$coef
      r1n = lm(Y[index10] ~ 0 + X[index10, ])$coef
      r0n = lm(Y[index00] ~ 0 + X[index00, ], weights = w0n)$coef
    }
    r1a = lm(Y[index11] ~ 0 + X[index11, ], weights = w1a)$coef
    r0a = lm(Y[index01] ~ 0 + X[index01, ])$coef
    
    #weighted outcomes
    if (trc == F) {
      weighted.Y.c1 = Y[index11]*w1c
      weighted.Y.c0 = Y[index00]*w0c
      weighted.Y.n0 = Y[index00]*w0n
    }
    weighted.Y.a1 = Y[index11]*w1a
    
    #CACE, NACE and AACE
    if (trc == F) {
      CACE = mean(weighted.Y.c1) - mean(weighted.Y.c0)
      NACE = mean(Y[index10]) - mean(weighted.Y.n0)
    }
    AACE = mean(weighted.Y.a1) - mean(Y[index01])
    
    #weighted outcomes for regression estimator
    if (trc == F) {
      weighted.Y1c = (Y[index11]-X[index11, ]%*%r1c)*w1c
      weighted.Y0c = (Y[index00]-X[index00, ]%*%r0c)*w0c
      weighted.Y1n = Y[index10]-X[index10, ]%*%r1n
      weighted.Y0n = (Y[index00]-X[index00, ]%*%r0n)*w0n
      weighted.rc = rbind(X[index11, ]*w1c, X[index00, ]*w0c) %*% (r1c - r0c)
      weighted.rn = rbind(X[index10, ], X[index00, ]*w0n) %*% (r1n - r0n)
    }
    weighted.Y1a = (Y[index11]-X[index11, ]%*%r1a)*w1a
    weighted.Y0a = Y[index01]-X[index01, ]%*%r0a
    weighted.ra = rbind(X[index11, ]*w1a, X[index01, ]) %*% (r1a - r0a)
    
    #CACE, NACE and AACE, regression estimates
    if (trc == F) {
      CACE.reg = mean(weighted.Y1c) - mean(weighted.Y0c) + mean(weighted.rc)
      NACE.reg = mean(weighted.Y1n) - mean(weighted.Y0n) + mean(weighted.rn)
    }
    AACE.reg = mean(weighted.Y1a) - mean(weighted.Y0a) + mean(weighted.ra)
    
    #results
    if (trc == F) {
      ACE = list(CACE = CACE, CACE.reg = CACE.reg, 
                 NACE = NACE, NACE.reg = NACE.reg, 
                 AACE = AACE, AACE.reg = AACE.reg,  
                 beta.a = ps.score.fit$beta.a, beta.n = ps.score.fit$beta.n)
    }
    else {
      ACE = list(AACE = AACE, AACE.reg = AACE.reg,  
                 beta.a = ps.score.fit$beta.a, beta.n = ps.score.fit$beta.n)
    }
    return(ACE)
    
  }
}
```

Given their estimation functions, we use the simulated data ***data\_simu*** to show the application
```{r simu_PS_est, message = FALSE, warning = FALSE, paged.print = FALSE, eval = T, include = T}
res_PS <- PSPS_M_weighting(Z = data_simu$Z, 
                           D = data_simu$S, 
                           X = as.matrix(data_simu[, 2:4]), 
                           Y = data_simu$Y,
                           trc = FALSE, 
                           ep1 = 1, 
                           ep0 = 1,
                           beta.a = NULL,
                           beta.n = NULL)
  
res_PS_AACE <- c(res_PS$AACE, res_PS$AACE.reg)
res_PS_CACE <- c(res_PS$CACE, res_PS$CACE.reg)
res_PS_NACE <- c(res_PS$NACE, res_PS$NACE.reg)

res_PS_AACE
res_PS_CACE
res_PS_NACE

  
```


Next, we present the R code for the five estimation methods provided by Jiang et al. (2022), which is in their R pcakge ***pace***. This package can be installed using the following R code and can be found on web page <https://github.com/shuyang-stat/pace>.  
```{r simu_MR_inst, message = FALSE, warning = FALSE, paged.print = FALSE, eval = F, include = T}
devtools::install_github("shuyang1987/pace")
```

```{r simu_MR_est, message = FALSE, warning = FALSE, paged.print = FALSE, eval = T, include = T}
library(pace)
    
res_MR <-  pace::pace(X = as.matrix(data_simu[, c(2:4)]),
                        Z = data_simu$Z,
                        S = data_simu$S,
                        Y = data_simu$Y,
                        family.Y="gaussian",
                        nboot = 500 # bootstrap times
                      )

# For AACE:
res_MR_AACE <- c(res_MR$tau11w, res_MR$tau11sw, res_MR$tau11reg, res_MR$tau11reg2, res_MR$tau11aw)
res_MR_AACE
# For CACE:
res_MR_CACE <- c(res_MR$tau10w, res_MR$tau10sw, res_MR$tau10reg, res_MR$tau10reg2, res_MR$tau10aw)
res_MR_CACE
# For NACE:
res_MR_CACE <- c(res_MR$tau00w, res_MR$tau00sw, res_MR$tau00reg, res_MR$tau00reg2, res_MR$tau00aw)
res_MR_CACE
```
where ***11*** corresponds to ***AACE***, ***10*** corresponds to ***CACE***, ***00*** corresponds to ***NACE***.


## Reference

 - D. B. Rubin. Estimating causal effects of treatments in randomized and nonrandomized
studies. J Educ Psychol, 66(5): 688–701, 1974.
 - C.E. Frangakis and D. B. Rubin. Principal stratification in causal inference. Biometrics, 58(1):21–29, 2002.
 - P. Ding and J. Lu. Principal stratification analysis using principal scores. Journal of the Royal Statistical Society Series B: Statistical Methodology, 79(3):757–777, 2017.
 - Z. Jiang, S. Yang, and P. Ding. Multiply robust estimation of causal effects under principal ignorability. Journal of the Royal Statistical Society Series B: Statistical Methodology, 84(4):1423–1445, 2022.








