---
title: "Estimation Methods for Intercurrent Events"
author: "Yujing Gao"
date: "2025-09-15"
categories: [intercurrent event, per-protocol method, causal inference, principal stratification, multiple robust]
image: "relationship.png"
---

::: {style="text-align: justify;"}
## 1. The General Introduction of Estimand Framework

The general introduction of estimand framework includes four parts:

-   Trial Objective

-   Estimand

-   Main Estimator

-   Main Estimate

An **estimand** is a precise description of the treatment effect reflecting the clinical question posed by a given clinical trial objective, via specifying five attributes: Population, Treatment, Endpoint, Population-level Summary, Intercurrent Events.

The **intercurrent event** is an event that occurs after treatment initiation and affects either the interpretation or existence of the measurements associated with the clinical outcome.

There are **five strategies (page 101-118 of ICH E9)** to deal with intercurrent events: treatment policy, hypothetical, composite variable, while on treatment, principal stratum. We will introduce these five strategies in next Section.

## 2. The Five Strategies

### 2.1 Treatment Policy

The treatment policy strategy includes all post-randomization data, regardless of the intercurrent events. In this approach, the primary analysis treats the occurrence of intercurrent events as part of the real-world scenario. Thus, data is collected and analyzed as if all patients followed the initial treatment assignment, irrespective of deviations. (Intention to treat - ITT)

Example: A clinical trial where patients switch to a different medication due to adverse effects, but all data (pre- and post-switch) are included in the primary analysis.

```{r stg1, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("stg1.png")
```

### 2.2 Hypothetical

The hypothetical strategy considers what the outcome would have been if the intercurrent event had not occurred. This strategy relies on assumptions to model the data based on a scenario where patients had continued as initially intended, disregarding the actual intercurrent events.

Example: Estimating the effect of a drug assuming that all patients remained on the assigned treatment without any dropouts or additional medications.

The hypothetical scenario should consider reasonable situations, e.g. a scenario where a toxic medicine is considered to be non-toxic is not usually relevant for decision making.

```{r stg2, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("stg2.png")
```

### 2.3 Composite Variable

In the composite variable strategy, the intercurrent event is integrated into the outcome itself, redefining it as part of a combined endpoint. This method allows for a new outcome that includes both the clinical endpoint and the intercurrent event, allowing analyses to capture their joint effect.

Example: For a heart disease trial, combining hospitalization and mortality as a composite endpoint, rather than separating them, captures the total adverse outcomes.

```{r stg3, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("stg3.png")
```

### 2.4 While-on-Treatment

The while-on-treatment strategy (also known as the on-treatment strategy) restricts analysis to data collected up until the occurrence of the intercurrent event. Once the intercurrent event occurs, further data is excluded from the analysis. This approach only considers the efficacy of the treatment while patients are actively taking it.

Example: Including data from patients only while they adhere to the medication and excluding data collected after discontinuation or switch to another treatment.

```{r stg4, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("stg4.png")
```

### 2.5 Principal Stratum

The principal stratum strategy analyzes only a specific subset of patients defined by their response to the intercurrent event, such as those who would not experience the event regardless of the treatment they received. This strategy requires assumptions about which patients would fall into this subset and generally involves a more complex statistical model.

Example: In a study where some patients are likely to need additional therapy, the analysis might focus only on those who would not require additional therapy regardless of the treatment arm they are in.

```{r stg5, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("stg5.png")
```

## 3. An Simple Example

Primary Estimand: to assess the outcome of new medicine (treatment group) as compared to old medicine (control group) in defined population who complete the treatment regimen.

```{r vaccine_exp, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("simple_exp.png")
```

## 4. Principal Stratification Framework

### 4.1. Principal Strata

Under the potential outcome framework (Rubin; 1974), each subject has potential outcomes $S(z)$ and $Y(z)$, where $z=0,1$. Frangakis and Rubin (2002) defined the principal stratification variable, $U=S(1)S(0)$, where $S(0),S(1)\in\{0,1\}$. Thus, there are four principal strata:

-   $U=00$: Never-adherence

-   $U=10$: Treatment-benefit adherence

-   $U=01$: Control-benefit adherence

-   $U=11$: Always-adherence

Take $U=S(1)S(0) = 00$ Never-adherence as an example:

-   $S(1) = 0$: when subject is assigned to the treatment group, she/he will not adhere to the protocol.

-   $S(0) = 0$: when subject is assigned to the control group, she/he will not adhere to the protocol.

Below we show the relationship between principal strata and the observed strata.

```{r relationship, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("relationship.png")
```

### 4.2. Principal Causal Effects (PCEs)

The causal estimand here is defined as principal causal effects (PCEs): $$\tau_{U=S(1)S(0)} = E\{Y(1) - Y(0) | U = S(1)S(0)\},\quad S(1)S(0) = 00, 10, 11, 01.$$

In Section 2's example, our interested parameter is PCE in Always-adherence strata: $$\tau_{11} = \tau_{U=11} = E\{Y(1) - Y(0)| U= 11\}.$$

### 4.3. Per-protocol Method

Here we also list the target estimand in Per-protocol method using our notation: $$\tau_{pp} = E(Y|Z=1,S=1) - E(Y|Z=0,S=1)$$

In Section 2's example, the interested parameter in the Per-protocol method corresponding to PCE in Always-adherence strata is: $$\tau_{11} = \tau_{U=11} = E\{Y(1) - Y(0)| U= 11\}.$$

However, $\tau_{11}$ is defined on the potential principal strata $U=S(1)S(0) = 11$, while $\tau_{pp}$ is defined on the observed strata $(Z,S)$.

Here we can use a simple table to show the relationship between principal strata abd observed strata:

```{r simple_table, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("simple_table.png")
```

Thus, if we use the Per-protocol method to estimate $\tau_{11}$, $\widehat{\tau}_{pp}$ may not be an consistent estimator for $\tau_{11}$ since it will be confounded by two other principal strata $U = 01$ and $U=10$.

## 5. Principal Stratification Estimation Methods

### 5.1 Identification Assumptions

We first represent the identification assumptions for the principal causal effects (Jiang et al.; 2022).

-   **Assumption 1**: SUTVA (Stable Unit Treatment Value Assumption): There is no interference and no hidden variations of treatment.

    -   This assumption hold in the completely randomized trial.

-   **Assumption 2**: Treatment Ignorability: $Z\perp \{S(0), S(1), Y(0), Y(1)\}| \boldsymbol{X}$.

    -   This assumption hold in the completely randomized trial.

-   **Assumption 3**: Monotonicity: $S(1)\geq S(0)$.

    -   This rules out stratum U=01 (Control-benefit adherence).
    -   This means: when participants are assigned to the treatment group, they are more likely to adhere to protocol comparing with when participants are assigned to the control group.
    -   Under Assumption 3, the relationship table between the principal strata and the observed strata changed.
    -   Now $\tau_{pp}$ is still confounded by the principal strata $U=10$.

```{r relationship1, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("relationship1.png")
```

-   **Assumption 4**: Principal Ignorability: $$E\{Y(1) | U=11, \boldsymbol{X}\} = E\{Y(1) | U=10, \boldsymbol{X}\} $$ $$E\{Y(0) | U=00, \boldsymbol{X}\} = E\{Y(0) | U=10, \boldsymbol{X}\} $$

    -   This requires that the expectations of the potential outcome do not vary across some principal strata U conditional on the covariates.
    -   Take the first formula as an example. Under Assumption 1-3, the first formula is equivalent to \begin{align*}
         Z=1,S=1:\quad  & E\{Y(1)| U = 11, Z=1,S=1, \boldsymbol{X}\} \\
         = &  E\{Y(1)| U = 10, Z=1, S=1, \boldsymbol{X}\}\\
         = &  E\{Y | Z=1,S=1,\boldsymbol{X}\}.
         \end{align*}
    -   This assumption help build an bridge to connect observed data with potential outcome. Thus, we can use observed data to estimate the principal causal effect.

```{r relationship2, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("relationship2.png")
```

### 5.2. Most Recent Principal Stratification Methods:

Under the identification assumptions listed in Section 5.1, we present the corresponding estimation methods and provide one plot to show the relationship among these methods.

```{r recent_method, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("recent_method.png")
```

#### 5.2.0 Notations

Before we provide the formula of each estimation method, we first provide the following notation based on the observed data $\boldsymbol{X}$, $Z$, $S$, and $Y$.

Define:

-   the propensity score of $Z$ or the treatment probability given the covariates: $\pi(\boldsymbol{X}) = P(Z=1|\boldsymbol{X})$.

-   the probability of the intermediate variable $S$ conditional on the treatment and covariates: $p_z(\boldsymbol{X}) = P(S=1|Z=z,\boldsymbol{X})$ for $z=0,1$.

-   the principal score of $S$: $$
    e_{10}(\boldsymbol{X}) = p_1(\boldsymbol{X}) - p_0(\boldsymbol{X}),\quad e_{00}(\boldsymbol{X}) = 1- p_1(\boldsymbol{X}), \quad e_{11}(\boldsymbol{X}) = p_0(\boldsymbol{X}).
    $$

-   the outcome mean within the observed group ($Z=z,S=s$): $\mu_{zs}(\boldsymbol{X}) = E(Y|Z=z, S=s,\boldsymbol{X})$ for $z,s=0,1$.

-   the marginalized probability of $S$ over the distribution of the covariates: $p_z = E\{p_z(\boldsymbol{X})\}$ for $z=0,1$.

#### 5.2.1 Principal Score Methods (Ding et al.; 2017)

The two estimators provided in Ding et al. (2017) rely on the principal score model for $S$, $p(\boldsymbol{X})$, and the outcome mean model for $Y$, the linear model fitted by $\beta \boldsymbol{X}$.

```{r method1, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("method1.png")
```

#### 5.2.2 Multiple Robust Methods (Jiang et al.; 2017)

First, we list two estimators that rely on the propensity score model for Z, $\pi(\boldsymbol{X})$, and the principal score model for S, $p(\boldsymbol{X})$.

```{r method2, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("method2.png")
```

Second, we introduce two estimators that rely on the outcome mean model for Y, $\mu(\boldsymbol{X})$, and the principal score model for S, $p(\boldsymbol{X})$.

```{r method3, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("method3.png")
```

Finally, we present the multiple robust estimator, which relies on all three models: the propensity score model for Z, $\pi(\boldsymbol{X})$; the principal score model for S, $p(\boldsymbol{X})$; the outcome mean model for Y, $\mu(\boldsymbol{X})$.

```{r method4, message=FALSE, warning=FALSE, paged.print=FALSE, eval = T, echo = F, include = T, fig.align='center'}
knitr::include_graphics("method4.png")
```

## 6. Simple Simulation

In this section, we use an simple simulation to show the codes for these principal stratification estimation methods and the Per-protocol method.

### 6.1 Simulation Setting

We follow the setting in Section 2.1, where we have three baseline variables:

-   $X_1$: Sex, binary, Bernoulli distribution with probability 0.5 as 1 (female)

-   $X_2$: Some transformed variable, binary, Bernoulli distribution with probability 0.8 as 1

-   $X_3$: Age, continuous, normal distribution with mean 50 and variance 8

In addition, we use the logistic model to generate the intercurrent event:

$$P(S=1|Z, \boldsymbol{X}) = logistic(-1 + Z +0.6X_1 - 0.4 X_2 + 0.02*X_3 )$$ and we use the linear regression model to generate the observed outcome:

$$ Y = 0.5 - 0.3Z + 0.7S + 0.2X_1 -0.2 X_2 + 0.01X_3 + 0.1X_1Z + 0.01 X_3 S + \epsilon$$ where $\epsilon\sim N(0, \sigma^2 = 0.4^2)$.

Under this simulation setting, we represent the following R code to generate the simulated data.

```{r simu_gen, message = FALSE, warning = FALSE, paged.print = FALSE, eval = T, include = T}
library(dplyr)

###################################
######  Simulation function  ######

S_coef_simu <- c(-1, # intercept,
                 1, # coef of Z, 
                 0.6, # coef of Sex, 
                 -0.4, # coef of Trans,
                 0.02 # coef of Age
                 )
Y_coef_simu <-  c(0.5, # intercept,
                  -0.3, # coef of Z
                  0.7, # coef of S
                  0.2, # coef of Sex
                  -0.2, # coef of Trans
                  0.01, # coef of Age
                  0.1, # coef of Sex * Z
                  0.01 # coef of Age * S 
)

# Based on vaccine data, we have 3 baseline covariates:
#  Sex (binary), transformed variable (binary), age (continuous)
f_sim <- function(N = 200*2, # sample size for two groups
                  seed = 123, # random seed
                  pi_Z = 0.5, # treatment propensity score: ratio of treatment / control, constant
                  male_p = 0.5, # ratio of male
                  trans_p = 0.8, # ratio of transformed variable
                  age_mu = 50, # mean of age
                  age_sd = 4, # sd of age
                  S_coef = S_coef_simu,
                  Y_coef = Y_coef_simu, 
                  Y_sd = 0.4
){
  
  set.seed(seed)
  
  ## Generate baseline variables
  Sex <- rbinom(n = N, size = 1, prob = male_p) # 1 means male, 0 means female
  Trans <- rbinom(n = N, size = 1, prob = trans_p) 
  Age <- rnorm(n = N, mean = age_mu, sd = age_sd)
  
  ## Generate treatment assignment Z (Z = 1, treatment)
  Z <- rbinom(N, size = 1, prob = pi_Z) 

  ## Generate intermediate variable (S = 1, adherence)
  XZ_matrix <- matrix(c(rep(1, N), 
                        Z,
                        Sex,
                        Trans,
                        Age),
                        nrow = N, 
                        byrow = F)
  S_prob <-  1 / (1 + exp(- XZ_matrix %*% S_coef))
  S <- apply(S_prob, 1, function(prob){
     rbinom(1, size = 1, prob = prob)
  })

  ## Generate outcome Y
  XZS_matrix <- matrix(c(rep(1, N), 
                       Z,
                       S,
                       Sex,
                       Trans,
                       Age,
                       Sex * Z,
                       Age * S),
                    nrow = N, 
                    byrow = F)
  Y_mu <- XZS_matrix %*% Y_coef 
  Y <- rnorm(N, mean = Y_mu, sd = Y_sd)
  
  data <- data.frame(Z,
                     Sex,
                     Trans,
                     Age,
                     S,
                     Y
  )
  
  return(data)
  
}

data_simu <- f_sim(N = 1000*2)
head(data_simu)

```

### 6.2 True Value Calculation

We also provide the code for calculating the true values of both the per-protocol effect $\tau_{pp}$ and each principal causal effect $\tau_{11}$, $\tau_{10}$, $\tau_{00}$.

First, for the true value of the per-protocol method $\tau_{pp}$, we generate a large simulated data with sample size $10^6$ and then calculate the true value of $\tau_{pp}$ as: $$\tau_{pp}^{true} = \widehat{E}\{Y|Z=1,S=1\} - \widehat{E}\{Y|Z=0,S=1\}.$$

```{r true_value_pp, message = FALSE, warning = FALSE, paged.print = FALSE, eval = T, include = T}
set.seed(123)
data_true <- f_sim(N = 10^6)

# True value for per-protocol effect
tau_pp <- mean(filter(data_true, Z == 1, S == 1)$Y) - mean(filter(data_true, Z == 0, S == 1)$Y)
tau_pp 
```

Next, for the true value of the principal causal effects $\tau_{11}$, $\tau_{10}$ and $\tau_{00}$. We use the identification result in Theorem 1 provided in Jiang et al. (2022):

-   

    (a) Based on the treatment probability and principal score:

$$
Always-adherence: \tau_{11}^{true} = 
 E\left\{\frac{e_{11}(\boldsymbol{X})}{ p_0} \frac{S}{p_1(\boldsymbol{X})} \frac{Z}{\pi(\boldsymbol{X})} Y\right\} - E\left\{ \frac{S}{p_0} \frac{1-Z}{1-\pi(\boldsymbol{X})} Y\right\}
$$

$$
Treatment-benefit-adherence: \tau_{10}^{true} = E\left\{\frac{e_{10}(\boldsymbol{X})}{p_1-p_0} \frac{S}{p_1(\boldsymbol{X})} \frac{Z}{\pi(\boldsymbol{X})} Y \right\} -
E\left\{\frac{e_{10}(\boldsymbol{X})}{p_1-p_0} \frac{1-S}{1-p_0(\boldsymbol{X})} \frac{1-Z}{1 - \pi(\boldsymbol{X})} Y \right\}
$$

$$
    Never-adherence: \tau_{00}^{true} = E\left\{\frac{1-S}{1-p_1} \frac{Z}{\pi(\boldsymbol{X})} Y \right\} - 
E\left\{\frac{e_{00}(\boldsymbol{X})}{1-p_1}\frac{1-S}{1-p_0(\boldsymbol{X})} \frac{1-Z}{1-\pi(\boldsymbol{X})} Y \right\} 
$$

-   

    (b) Based on the treatment probability and outcome mean: $$
        Always-adherence: \tau_{11}^{true} = 
        E\left[\frac{S(1-Z)/ \{1-\pi(\boldsymbol{X})\}}{p_0} \{\mu_{10}(\boldsymbol{X}) - \mu_{00}(\boldsymbol{X})\}\right] 
        $$

$$
Treatment-benefit-adherence: \tau_{10}^{true} = 
E\left[ \frac{SZ/\pi(\boldsymbol{X}) - S(1-Z)/\{1-\pi(\boldsymbol{X})\}}{p_1 - p_0} \left\{\mu_{11}(\boldsymbol{X}) - \mu_{00}(\boldsymbol{X})\right\}\right] 
$$

$$
    Never-adherence: \tau_{00}^{true} = E\left[ \frac{1-SZ/\pi(\boldsymbol{X})}{1-p_1} \{\mu_{11}(\boldsymbol{X}) - \mu_{00}(\boldsymbol{X})\} \right]
$$

-   

    (c) Based on the principal score and outcome mean: $$
        Always-adherence: \tau_{11}^{true} = E\left[\frac{p_0(\boldsymbol{X})}{p_0} \{\mu_{11}(\boldsymbol{X}) - \mu_{01}(\boldsymbol{X})\}\right] 
        $$

$$
Treatment-benefit-adherence: \tau_{10}^{true} = E\left[\frac{p_1(\boldsymbol{X}) - p_0(\boldsymbol{X}) }{p_1-p_0} \{\mu_{11}(\boldsymbol{X}) - \mu_{00}(\boldsymbol{X})\} \right]
$$

$$
    Never-adherence: \tau_{00}^{true} = E\left[\frac{1-p_1(\boldsymbol{X})}{1-p_1} \{\mu_{10}(\boldsymbol{X}) - \mu_{00}(\boldsymbol{X})\}\right] 
$$

```{r true_value_pce, message = FALSE, warning = FALSE, paged.print = FALSE, eval = T, include = T}
###### Calculate the true value for PCE ######
# the true value is not stable in this strata
tau10 <- function(data,
                  S_coef = S_coef_simu,
                  Y_coef = Y_coef_simu){
  Z <- data$Z
  S <- data$S
  Y <- data$Y
  X1 <- data$Sex
  X2 <- data$Trans
  X3 <- data$Age
  
  p1_X <- 1 / (1 + exp(- (S_coef[1] + S_coef[2] * 1 + S_coef[3] * X1 + S_coef[4] * X2 + S_coef[5] * X3)))
  p0_X <- 1 / (1 + exp(- (S_coef[1] + S_coef[2] * 0 + S_coef[3] * X1 + S_coef[4] * X2 + S_coef[5] * X3)))
  
  p1 <- mean(p1_X)
  p0 <- mean(p0_X)
  
  e_10_X <- p1_X - p0_X
  e_00_X <- 1 - p1_X
  e_11_X <- p0_X
  
  mu_11_X <- Y_coef[1] + Y_coef[2] * 1 + Y_coef[3] * 1 + Y_coef[4] * X1 +
    Y_coef[5] * X2 + Y_coef[6] * X3 + Y_coef[7] * X1 * 1 + Y_coef[8] * X3 * 1
  mu_00_X <- Y_coef[1] + Y_coef[2] * 0 + Y_coef[3] * 0 + Y_coef[4] * X1 +
    Y_coef[5] * X2 + Y_coef[6] * X3 + Y_coef[7] * X1 * 0 + Y_coef[8] * X3 * 0
  
  res_a <- mean(e_10_X*S*Z*Y / (p1-p0) / p1_X / (1/2) ) - 
          mean(e_10_X * (1-S) * (1-Z) * Y / (p1-p0) / (1-p0_X)/ (1/2))
  res_b <- mean( ((S * Z / (1/2)) - S * (1 - Z) / (1/2)) * (mu_11_X - mu_00_X) / (p1-p0))
  res_c <-  mean((p1_X - p0_X) * (mu_11_X - mu_00_X) / (p1 - p0) )
  
  return(c(res_a, res_b, res_c))
}

tau00 <- function(data,
                  S_coef = S_coef_simu,
                  Y_coef = Y_coef_simu){
  Z <- data$Z
  S <- data$S
  Y <- data$Y
  X1 <- data$Sex
  X2 <- data$Trans
  X3 <- data$Age
 
  p1_X <- 1 / (1 + exp(- (S_coef[1] + S_coef[2] * 1 + S_coef[3] * X1 + S_coef[4] * X2 + S_coef[5] * X3)))
  p0_X <- 1 / (1 + exp(- (S_coef[1] + S_coef[2] * 0 + S_coef[3] * X1 + S_coef[4] * X2 + S_coef[5] * X3)))
    
  p1 <- mean(p1_X)
  p0 <- mean(p0_X)
  
  e_00_X <- 1 - p1_X
  
  mu_10_X <- Y_coef[1] + Y_coef[2] * 1 + Y_coef[3] * 0 + Y_coef[4] * X1 +
           Y_coef[5] * X2 + Y_coef[6] * X3 + Y_coef[7] * X1 * 1 + Y_coef[8] * X3 * 0
  mu_00_X <- Y_coef[1] + Y_coef[2] * 0 + Y_coef[3] * 0 + Y_coef[4] * X1 +
           Y_coef[5] * X2 + Y_coef[6] * X3 + Y_coef[7] * X1 * 0 + Y_coef[8] * X3 * 0
  
  res_a <- mean((1 - S)*Z*Y / (1 - p1)/(1/2)) - mean(e_00_X * (1-S)*(1-Z)*Y / (1-p1) / (1-p0_X)/ (1/2))
  res_b <- mean( (1 - S*Z/(1/2)) / (1 - p1) *  (mu_10_X - mu_00_X))
  res_c <- mean((1-p1_X)/(1-p1) * (mu_10_X - mu_00_X) )
  
 return(c(res_a, res_b, res_c))
}

tau11 <- function(data, 
                  S_coef = S_coef_simu,
                  Y_coef = Y_coef_simu){
  Z <- data$Z
  S <- data$S
  Y <- data$Y
  X1 <- data$Sex
  X2 <- data$Trans
  X3 <- data$Age
  
  p1_X <- 1 / (1 + exp(- (S_coef[1] + S_coef[2] * 1 + S_coef[3] * X1 + S_coef[4] * X2 + S_coef[5] * X3)))
  p0_X <- 1 / (1 + exp(- (S_coef[1] + S_coef[2] * 0 + S_coef[3] * X1 + S_coef[4] * X2 + S_coef[5] * X3)))
  
  p1 <- mean(p1_X)
  p0 <- mean(p0_X)
  
  e_11_X <- p0_X
  
  mu_11_X <- Y_coef[1] + Y_coef[2] * 1 + Y_coef[3] * 1 + Y_coef[4] * X1 +
    Y_coef[5] * X2 + Y_coef[6] * X3 + Y_coef[7] * X1 * 1 + Y_coef[8] * X3 * 1
  mu_01_X <- Y_coef[1] + Y_coef[2] * 0 + Y_coef[3] * 1 + Y_coef[4] * X1 +
    Y_coef[5] * X2 + Y_coef[6] * X3 + Y_coef[7] * X1 * 0 + Y_coef[8] * X3 * 1
  
  res_a <- mean(e_11_X*S*Z*Y / p0 / p1_X / (1/2) ) - 
    mean( S * (1-Z) * Y / p0 / (1/2))
  res_b <- mean( S*(1-Z) / (1/2) / p0 * (mu_11_X - mu_01_X) )
  res_c <-  mean( p0_X / p0 * (mu_11_X - mu_01_X))
  
 return(c(res_a, res_b, res_c))
}

tau11_true <- tau11(data_true)
tau10_true <- tau10(data_true)
tau00_true <- tau00(data_true)

tau11_true
tau10_true
tau00_true

```

### 6.3 Estimation

Here we show R codes for principal stratification estimation. First, for the two estimation methods provided by Ding et al. (2017), below is the original R code provided within their paper:

```{r simu_PS_fun, message = FALSE, warning = FALSE, paged.print = FALSE, eval = T, include = T}
# Ding's original estimation code
{
  ##################################################################
  ######################## EM Algorithm for ########################
  #### Principal Stratification Analysis using Propensity Score ####
  ######################## With Monotonicity #######################
  ###################### Ding and Lu 2015 Oct ######################
  ##################################################################
  
  
  ##propensity score method, with covariate adjustment and sensitivity analysis for GPI
  #the package used for multivariate logistic regression
  library(nnet)
  
  #Preliminary function: principal score calculation 
  #Z: randomization
  #D: treatment received
  #X: pretreatment covaraites, 11111 in the first column
  #beta.a, beta.n: initial values for the paramaters in the multiple logistic regression
  #iter.max: total number of iterations
  #error0: convergence error rate
  #Trace: if TRUE then trace each EM iteration
  #fitting multinomial logistic regression model with principal stratification variable as missing data
  PS_pred = function(Z, D, X, 
                     beta.a = NULL, beta.n = NULL, 
                     iter.max = 200, error0 = 10^-6, Trace = FALSE) {  
    V = dim(X)[2]
    N = length(Z)
    if(is.null(beta.a)) beta.a = rep(0, V)
    if(is.null(beta.n)) beta.n = rep(0, V)  
    
    iter = 1         
    repeat{
      
      ##initial values of iteration
      beta.a_old = beta.a
      beta.n_old = beta.n
      
      if(Trace == T) {
        print(paste("The ", iter, "-th EM iteration!", sep=""))
      }
      
      #E step: posterior probabilities
      #and the augmented data set with weights
      #creat a null matrix for the augmented data set AugData
      AugData = NULL
      #each individual correspond to 1 or 2 individuals in the augmented data set
      for(i in 1:N) {
        if(Z[i]==1&D[i]==1) {
          #posterior probabilities
          prob.c = 1/(1 + exp(t(beta.a_old)%*%X[i, ]))
          prob.a = 1 - prob.c
          
          AugData = rbind(AugData, c(1, X[i, ], prob.c))
          AugData = rbind(AugData, c(2, X[i, ], prob.a))
        }
        
        if(Z[i]==1&D[i]==0) {
          AugData = rbind(AugData, c(3, X[i, ], 1))  
        }
        
        if(Z[i]==0&D[i]==1) {
          AugData = rbind(AugData, c(2, X[i, ], 1))  
        }
        
        if(Z[i]==0&D[i]==0) {
          #posterior probabilities
          prob.c = 1/(1 + exp(t(beta.n_old)%*%X[i, ]))
          prob.n = 1 - prob.c
          
          AugData = rbind(AugData, c(1, X[i, ], prob.c))
          AugData = rbind(AugData, c(3, X[i, ], prob.n))  
          
        }#for if
        
      }#for "for"
      #make AugData into a dataframe
      #AugData = data.frame(AugData)
      #colnames(AugData) = c("U", "X", "Weight")
      #Multinomial logistic regression using "nnet" package
      
      fit = multinom(AugData[, 1] ~ AugData[, (3:(V+1))], weights = AugData[, (V+2)], trace = FALSE)
      betas  = coef(fit)
      beta.a = betas[1, ]
      beta.n = betas[2, ]
      
      iter = iter + 1
      error = sum((beta.a - beta.a_old)^2)  + sum((beta.n - beta.n_old)^2)
      if(iter>iter.max||error<error0)   break           
      
    }#for repeat
    
    #the predicted probabilities
    #three columns corresponding to the adherence, always taker and never taker
    PROB = matrix(0, N, 3)
    for(i in 1:N) {
      prob.c = 1
      prob.a = exp(t(beta.a)%*%X[i, ])
      prob.n = exp(t(beta.n)%*%X[i, ])
      sum = prob.c + prob.a + prob.n
      
      PROB[i,] = c(prob.c, prob.a, prob.n)/sum
    }
    
    results = list(PROB=PROB, beta.a=beta.a, beta.n=beta.n)
    return(results)
  }
  
  #Main function
  #Z: randomization
  #D: treatment received
  #X: covariate matrix: the first column is NOT 11111
  #Y: outcome of interest
  #trc: truncation by death indicator, default FALSE. If TRUE only SACE (i.e. AACE) is calculated.
  #ep1, ep0: sensitivity parameters in Proposition 4, Section 6.1.
  #beta.a, beta.n: initial values for the paramaters in the multiple logistic regression
  PSPS_M_weighting = function(Z, D, X, Y, 
                              trc = FALSE, ep1 = 1, ep0 = 1,
                              beta.a = NULL, beta.n = NULL) {
    #augment the design X
    N = length(Z)
    X = cbind(rep(1, N), X)
    
    #estimate the propensity scores using Multinomial Logistic Regression
    #PS_pred returns three columns: c, a, n
    ps.score.fit = PS_pred(Z, D, X, beta.a = beta.a, beta.n = beta.n)
    ps.score     = ps.score.fit$PROB
    pr.n = sum(Z*(1 - D))/sum(Z)
    pr.a = sum((1 - Z)*D)/sum(1-Z)
    pr.c = 1 - pr.n - pr.a
    
    #indices
    index11 = (1:N)[Z==1&D==1]
    index10 = (1:N)[Z==1&D==0]
    index01 = (1:N)[Z==0&D==1]
    index00 = (1:N)[Z==0&D==0]
    
    #weights
    if (trc == F) {
      w1c = ep1*ps.score[index11, 1]/(ep1*ps.score[index11, 1] + ps.score[index11, 2])/pr.c*(pr.c + pr.a)
      w0c = ep0*ps.score[index00, 1]/(ep0*ps.score[index00, 1] + ps.score[index00, 3])/pr.c*(pr.c + pr.n)
      w0n = ps.score[index00, 3]/(ep0*ps.score[index00, 1] + ps.score[index00, 3])/pr.n*(pr.c + pr.n)
    }
    w1a = ps.score[index11, 2]/(ep1*ps.score[index11, 1] + ps.score[index11, 2])/pr.a*(pr.c + pr.a)
    
    #model assisted regression estimator 
    if (trc == F) {
      r1c = lm(Y[index11] ~ 0 + X[index11, ], weights = w1c)$coef
      r0c = lm(Y[index00] ~ 0 + X[index00, ], weights = w0c)$coef
      r1n = lm(Y[index10] ~ 0 + X[index10, ])$coef
      r0n = lm(Y[index00] ~ 0 + X[index00, ], weights = w0n)$coef
    }
    r1a = lm(Y[index11] ~ 0 + X[index11, ], weights = w1a)$coef
    r0a = lm(Y[index01] ~ 0 + X[index01, ])$coef
    
    #weighted outcomes
    if (trc == F) {
      weighted.Y.c1 = Y[index11]*w1c
      weighted.Y.c0 = Y[index00]*w0c
      weighted.Y.n0 = Y[index00]*w0n
    }
    weighted.Y.a1 = Y[index11]*w1a
    
    #CACE, NACE and AACE
    if (trc == F) {
      CACE = mean(weighted.Y.c1) - mean(weighted.Y.c0)
      NACE = mean(Y[index10]) - mean(weighted.Y.n0)
    }
    AACE = mean(weighted.Y.a1) - mean(Y[index01])
    
    #weighted outcomes for regression estimator
    if (trc == F) {
      weighted.Y1c = (Y[index11]-X[index11, ]%*%r1c)*w1c
      weighted.Y0c = (Y[index00]-X[index00, ]%*%r0c)*w0c
      weighted.Y1n = Y[index10]-X[index10, ]%*%r1n
      weighted.Y0n = (Y[index00]-X[index00, ]%*%r0n)*w0n
      weighted.rc = rbind(X[index11, ]*w1c, X[index00, ]*w0c) %*% (r1c - r0c)
      weighted.rn = rbind(X[index10, ], X[index00, ]*w0n) %*% (r1n - r0n)
    }
    weighted.Y1a = (Y[index11]-X[index11, ]%*%r1a)*w1a
    weighted.Y0a = Y[index01]-X[index01, ]%*%r0a
    weighted.ra = rbind(X[index11, ]*w1a, X[index01, ]) %*% (r1a - r0a)
    
    #CACE, NACE and AACE, regression estimates
    if (trc == F) {
      CACE.reg = mean(weighted.Y1c) - mean(weighted.Y0c) + mean(weighted.rc)
      NACE.reg = mean(weighted.Y1n) - mean(weighted.Y0n) + mean(weighted.rn)
    }
    AACE.reg = mean(weighted.Y1a) - mean(weighted.Y0a) + mean(weighted.ra)
    
    #results
    if (trc == F) {
      ACE = list(CACE = CACE, CACE.reg = CACE.reg, 
                 NACE = NACE, NACE.reg = NACE.reg, 
                 AACE = AACE, AACE.reg = AACE.reg,  
                 beta.a = ps.score.fit$beta.a, beta.n = ps.score.fit$beta.n)
    }
    else {
      ACE = list(AACE = AACE, AACE.reg = AACE.reg,  
                 beta.a = ps.score.fit$beta.a, beta.n = ps.score.fit$beta.n)
    }
    return(ACE)
    
  }
}
```

Given their estimation functions, we use the simulated data ***data_simu*** to show the application

```{r simu_PS_est, message = FALSE, warning = FALSE, paged.print = FALSE, eval = T, include = T}
res_PS <- PSPS_M_weighting(Z = data_simu$Z, 
                           D = data_simu$S, 
                           X = as.matrix(data_simu[, 2:4]), 
                           Y = data_simu$Y,
                           trc = FALSE, 
                           ep1 = 1, 
                           ep0 = 1,
                           beta.a = NULL,
                           beta.n = NULL)
  
res_PS_11 <- c(res_PS$AACE, res_PS$AACE.reg)
res_PS_10 <- c(res_PS$CACE, res_PS$CACE.reg)
res_PS_00 <- c(res_PS$NACE, res_PS$NACE.reg)

res_PS_11
res_PS_10
res_PS_00

```

Next, we present the R code for the five estimation methods provided by Jiang et al. (2022), which is in their R pcakge ***pace***. This package can be installed using the following R code and can be found on web page <https://github.com/shuyang-stat/pace>.

```{r simu_MR_inst, message = FALSE, warning = FALSE, paged.print = FALSE, eval = F, include = T}
devtools::install_github("shuyang1987/pace")
```

```{r simu_MR_est, message = FALSE, warning = FALSE, paged.print = FALSE, eval = T, include = T}
library(pace)
    
res_MR <-  pace::pace(X = as.matrix(data_simu[, c(2:4)]),
                        Z = data_simu$Z,
                        S = data_simu$S,
                        Y = data_simu$Y,
                        family.Y="gaussian",
                        nboot = 500 # bootstrap times
                      )


res_MR_11 <- c(res_MR$tau11w, res_MR$tau11sw, res_MR$tau11reg, res_MR$tau11reg2, res_MR$tau11aw)
res_MR_11
res_MR_10 <- c(res_MR$tau10w, res_MR$tau10sw, res_MR$tau10reg, res_MR$tau10reg2, res_MR$tau10aw)
res_MR_10
res_MR_00 <- c(res_MR$tau00w, res_MR$tau00sw, res_MR$tau00reg, res_MR$tau00reg2, res_MR$tau00aw)
res_MR_00

```

Now let's combine these 7 estimation results together.

```{r simu_est_res, message = FALSE, warning = FALSE, paged.print = FALSE, eval = T, include = T}

Est_res <- data.frame(est_method = c("Ding_naive", "Ding_reg", 
                                     "tau_w", "tau_sw", "tau_reg", "rau_reg2", "tau_aw"),
                      tau11_est = c(res_PS_11, res_MR_11),
                      tau11_bias = c(res_PS_11, res_MR_11) - tau11_true,
                      tau10_est = c(res_PS_10, res_MR_10),
                      tau10_bias = c(res_PS_10, res_MR_10) - tau10_true,
                      tau00_est = c(res_PS_00, res_MR_11),
                      tau00_bias = c(res_PS_00, res_MR_11) - tau00_true)

knitr::kable(Est_res, caption = "Estimation Result")
```

## Reference

-   D. B. Rubin. Estimating causal effects of treatments in randomized and nonrandomized studies. J Educ Psychol, 66(5): 688--701, 1974.
-   C.E. Frangakis and D. B. Rubin. Principal stratification in causal inference. Biometrics, 58(1):21--29, 2002.
-   P. Ding and J. Lu. Principal stratification analysis using principal scores. Journal of the Royal Statistical Society Series B: Statistical Methodology, 79(3):757--777, 2017.
-   Z. Jiang, S. Yang, and P. Ding. Multiply robust estimation of causal effects under principal ignorability. Journal of the Royal Statistical Society Series B: Statistical Methodology, 84(4):1423--1445, 2022.
:::
